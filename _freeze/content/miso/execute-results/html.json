{
  "hash": "77ac5a57e392fda0feff7e8144acb29e",
  "result": {
    "markdown": "---\ntitle: Misophonia Project\nexecute:\n  freeze: true \n---\n\n# Overview\n\n## What is misophonia?\n\nAlso, known as selective sound sensitivity syndrome or sound-rage, misophonia is a disorder in which certain sounds trigger emotional or physiological responses that some might perceive as unreasonable given the circumstance. Those who have misophonia might describe it as when a sound “drives you crazy.” Their reactions can range from anger and annoyance to panic and the need to flee.\n\n- [Misophonia on Wikipedia](https://en.wikipedia.org/wiki/Misophonia)\n\n- Ward, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., Traiser, C., ... & Keil, A. (2022). The Relationship Between Self-Reported Misophonia Symptoms and Auditory Aversive Generalization Leaning: A Preliminary Report. Frontiers in Neuroscience, 16, 899476. [https://doi.org/10.3389/fnins.2022.899476](https://doi.org/10.3389/fnins.2022.899476)\n- Farkas, A. H., Ward, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., ... & Keil, A. (2023). Auditory Aversive Generalization Learning Prompts Threat-Specific Changes in Alpha-Band Activity. bioRxiv, 2023-12. [https://doi.org/10.1101/2023.12.04.569971](https://doi.org/10.1101/2023.12.04.569971)\n- **Accepted Pre-registration**: Ward, R., Keil, A., Pouliot, J., Mears, R. P., Chiasson, P., & McIlvanie, S. (2021, September 27). Psychophysiological mechanisms underlying aversive conditioning in Misophonia.[https://doi.org/10.17605/OSF.IO/E26AD](https://doi.org/10.17605/OSF.IO/E26AD)\n\n- [Misophonia: Zotero Refs](https://www.zotero.org/groups/2418504/uf-ephys-misophonia/library)\n\n### Related concept (but not the same phenomenon)\n\nASMR (Autonomous sensory meridian response) is a tingling sensation that typically begins on the scalp and moves down the back of the neck and upper spine. A pleasant form of paresthesia, it has been compared with auditory-tactile synesthesia and may overlap with frisson.\n\n### Auditory Steady-State Response\n\n- Brugge, J. F., Nourski, K. V., Oya, H., Reale, R. A., Kawasaki, H., Steinschneider, M., & Howard III, M. A. (2009). Coding of repetitive transients by auditory cortex on Heschl's gyrus. Journal of neurophysiology, 102(4), 2358-2374. [https://doi.org/10.1152/jn.91346.2008](https://doi.org/10.1152/jn.91346.2008)\n\n- Popov, T., Oostenveld, R., & Schoffelen, J. M. (2018). FieldTrip made easy: an analysis protocol for group analysis of the auditory steady state brain response in time, frequency, and space. Frontiers in neuroscience, 12, 711.[https://doi.org/10.3389/fnins.2018.00711](https://doi.org/10.3389/fnins.2018.00711)\n\n- Pantev, C., Roberts, L. E., Elbert, T., Roβ, B., & Wienbruch, C. (1996). Tonotopic organization of the sources of human auditory steady-state responses. Hearing research, 101(1-2), 62-74.[]()\n\n- Parker, D. A., Hamm, J. P., McDowell, J. E., Keedy, S. K., Gershon, E. S., Ivleva, E. I., ... & Clementz, B. A. (2019). Auditory steady-state EEG response across the schizo-bipolar spectrum. Schizophrenia research, 209, 218-226. [https://doi.org/10.1016/j.schres.2019.04.014](https://doi.org/10.1016/j.schres.2019.04.014)\n\n\n### MNE-Python Workflow (Schematic)\n\n\n```{mermaid, echo=FALSE, warning=FALSE, message=FALSE}\n\n%%{init: {'theme':'forest'}}%%\n\ngraph LR;\n        subgraph Sensor-level-analysis\n\n       A[Decode time-by-time </br>  using a 'sliding' estimator] --> B[Time-frequency </br> decomposition] \n       B --> C[Decoding </br> based on </br> common spatial patterns] \n       C --> D[Noise covariance </br> estimation] \n       D --> E[Group average </br> at the </br> sensor level] \n   end\n  \n    subgraph Preprocessing\n\n       l1[Assess </br> channel-wise </br> data quality] --> l2[Estimate </br> head positions] \n       l2 --> l3[Apply low- and </br> high-pass filters] \n       l3 --> l4[Temporal regression </br> for artifact removal]\n       l4 --> l5a[Fit ICA] \n       l5a --> l6a[Find ICA </br> artifacts] \n       l4 --> l5b[Extract epochs] \n       l5b --> l7[Apply ICA] \n       l6a --> l7 --> l8[Remove epochs </br> based on  </br> PTP amplitudes]  \n       l5b --> l6b[Apply SSP] \n       l4 --> l5c[Compute SSP] \n       l5c --> l6b[Apply SSP] \n       l6b --> l8[Remove epochs </br> based on </br> PTP amplitudes] \n       l8 --> l9[Extract </br> evoked data for </br> each condition] \n       l9 --> l10[Decode pairs of </br>  conditions based on </br> entire epochs] \n    end\n    \n\n   \n   %%l0[Raw Data] --> l1\n   %%E --> F[Output </br> Statistical </br> Analysis Pipeline]    \n   \n   classDef green fill:#9f6,stroke:#333,stroke-width:0.5px;\n   classDef orange fill:#f96,stroke:#333,stroke-width:1px;\n   classDef white fill:#fff,stroke:#333,stroke-width:1px;\n   classDef sq stroke:#f66,stroke-width:1px;\n   classDef blue fill:#6699cc,stroke:#333,stroke-width:1px;\n   classDef red fill:#D32737,stroke:#FFF,stroke-width:1.5px;\n     \n   class Preprocessing,Sensor-level-analysis white\n\n```\n\n\n::: columns\n::: {.column width=\"50%\"}\n\n<https://github.com/mne-tools>\n\n::: \n::: {.column width=\"50%\"}\n\n<https://mne.tools/stable/index.html>\n\n\n:::\n:::\n\n\n### MNE-Python\n\n- [MNE-Python](https://mne.tools/stable/index.html) is a Python package for MEG and EEG data analysis.\n\n### MNE-BIDS\n\n- [MNE-BIDS](https://mne.tools/mne-bids/stable/index.html) is a Python package for converting data from the Brain Imaging Data Structure (BIDS) format to MNE-Python format.\n\n- [BIDS](https://bids.neuroimaging.io/) (Brain Imaging Data Structure) A simple and intuitive way to organize and describe your neuroimaging and behavioral data.\n\n### MNE-BIDS-Pipeline   \n\n- [MNE-BIDS-Pipeline](https://mne.tools/mne-bids-pipeline/stable/index.html) is a full-flegded processing pipeline Python package for preprocessing MEG and EEG data.\n\n\n\n#### Prepare your dataset\n\nMNE-BIDS-Pipeline only works with BIDS-formatted raw data.\n\n![](https://mne.tools/mne-bids/assets/MNE-BIDS.png)\n\n\n\n#### Create a configuration file\n\nAll parameters of the pipeline are controlled via a configuration file. Create a template:\n\n`mne_bids_pipeline --create-config=/path/to/custom_config.py`\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\n\nstudy_name = \"ds000247\"\nbids_root = f\"~/mne_data/{study_name}\"\nderiv_root = f\"~/mne_data/derivatives/mne-bids-pipeline/{study_name}\"\n\nsubjects = [\"0002\"]\nsessions = [\"01\"]\ntask = \"rest\"\ntask_is_rest = True\n\ncrop_runs = (0, 100)  # to speed up computations\n\nch_types = [\"meg\"]\nspatial_filter = \"ssp\"\n\nl_freq = 1.0\nh_freq = 40.0\n\nrest_epochs_duration = 10\nrest_epochs_overlap = 0\n\nepochs_tmin = 0\nbaseline = None\n```\n:::\n\n\n-   [from example ds000247](https://mne.tools/mne-bids-pipeline/stable/examples/ds000247.html#configuration)\n\n#### Run the pipeline\n\nA config file controls main pipeline parameters. CLI runs all (or part with an override).\n\n-   Re-running a specific stage of the pipeline for additional data\n    -   `mne_bids_pipeline --config=custom_config.py --steps=preprocessing --subjects=0051,0052,0053`\n-   Running the pipeline with different parameters for a specific stage (e.g., changing filter cutoffs, interpolating bad channels, etc.)\n    -   `mne_bids_pipeline --config=custom_config.py --steps=preprocessing/ica`\n-   Running the pipeline with different parameters for a specific subject or session\n    -   `mne_bids_pipeline --config=custom_config.py --steps=preprocessing/ica --session=cond --subjects=0051,0052,0053`\n\n#### Visualize the results (HTML reports)\n\n\n\n### Finding things on HiPerGator\n\n- [UF Research Computing Documentation](https://help.rc.ufl.edu/doc/UFRC_Help_and_Documentation)\n\n\nCorrect address for python env : \n\n`#!/usr/bin/bash\nexec /blue/psb4934/share/conda/envs/mne_1_6_0/mne/bin/python -m ipykernel \"$@\"`\n\n[Shared Conda environments on HiPerGator](https://uf-splab.github.io/open-neuro/content/posts/share-hpg-env/)\n\n",
    "supporting": [
      "miso_files"
    ],
    "filters": [],
    "includes": {}
  }
}
[
  {
    "objectID": "content/customizing.html",
    "href": "content/customizing.html",
    "title": "Customization",
    "section": "",
    "text": "Quarto allow many bells and whistles to make nice output. Read the documentation here Quarto documentation."
  },
  {
    "objectID": "content/customizing.html#quarto-documentation",
    "href": "content/customizing.html#quarto-documentation",
    "title": "Customization",
    "section": "",
    "text": "Quarto allow many bells and whistles to make nice output. Read the documentation here Quarto documentation."
  },
  {
    "objectID": "content/customizing.html#examples",
    "href": "content/customizing.html#examples",
    "title": "Customization",
    "section": "Examples",
    "text": "Examples\nLooking at other people’s Quarto code is a great way to figure out how to do stuff. Most will have a link to a GitHub repo where you can see the raw code. Look for a link to edit page or see source code. This will usually be on the right. Or look for the GitHub icon somewhere.\n\nQuarto gallery\nnmfs-openscapes\nFaye lab manual\nquarto-titlepages Note the link to edit is broken. Go to repo and look in documentation directory."
  },
  {
    "objectID": "content/acknowledgements.html",
    "href": "content/acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "This repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland.",
    "crumbs": [
      "Acknowledgements"
    ]
  },
  {
    "objectID": "content/add-content.html",
    "href": "content/add-content.html",
    "title": "Customize",
    "section": "",
    "text": "Edit the qmd or md files in the content folder. qmd files can include code (R, Python, Julia) and lots of Quarto markdown bells and whistles (like call-outs, cross-references, auto-citations and much more).\nEach page should start with\n---\ntitle: your title\n---\nand the first header will be the 2nd level, so ##. Note, there are situations where you leave off\n---\ntitle: your title\n---\nand start the qmd file with a level header #, but if using the default title yaml (in the --- fence) is a good habit since it makes it easy for Quarto convert your qmd file to other formats (like into a presentation)."
  },
  {
    "objectID": "content/add-content.html#edit-and-add-your-pages",
    "href": "content/add-content.html#edit-and-add-your-pages",
    "title": "Customize",
    "section": "",
    "text": "Edit the qmd or md files in the content folder. qmd files can include code (R, Python, Julia) and lots of Quarto markdown bells and whistles (like call-outs, cross-references, auto-citations and much more).\nEach page should start with\n---\ntitle: your title\n---\nand the first header will be the 2nd level, so ##. Note, there are situations where you leave off\n---\ntitle: your title\n---\nand start the qmd file with a level header #, but if using the default title yaml (in the --- fence) is a good habit since it makes it easy for Quarto convert your qmd file to other formats (like into a presentation)."
  },
  {
    "objectID": "content/add-content.html#add-your-pages-the-project",
    "href": "content/add-content.html#add-your-pages-the-project",
    "title": "Customize",
    "section": "Add your pages the project",
    "text": "Add your pages the project\n\nAdd the files to _quarto.yml"
  },
  {
    "objectID": "content/posts/pipeline-tutorial/index.html",
    "href": "content/posts/pipeline-tutorial/index.html",
    "title": "Tutorial on MNE-BIDS-Pipeline",
    "section": "",
    "text": "slides\n\n\n\n\n\ngraph LR;\n   epo_1--&gt;epo_1_prms;\n   epo_1_prms--&gt;epo_1_Fs;\n   epo_1_prms--&gt;epo_1_L;\n   epo_1_prms--&gt;epo_1_T;\n   epo_1_prms--&gt;epo_1_offset_pts;\n   epo_1_prms--&gt;epo_1_offset_t;\n   epo_1--&gt;epo_1_ops;\n   epo_1_ops--&gt;epo_1_seg_1;\n   epo_1_seg_1--&gt;epo_1_seg_1_prms;\n   epo_1_seg_1_prms--&gt;epo_1_seg_1_freq;\n   epo_1_seg_1_prms--&gt;epo_1_seg_1_n_cyc;\n   epo_1_seg_1_prms--&gt;epo_1_seg_1_ph_offset_r2pi;\n   epo_1_seg_1_prms--&gt;epo_1_seg_1_ph_offset_t;\n   epo_1_seg_1--&gt;epo_1_seg_1_ops;\n   epo_1_seg_1_ops--&gt;epo_1_seg_1_1;\n   epo_1_seg_1_ops--&gt;epo_1_seg_1_2;\n   epo_1_ops--&gt;epo_1_seg_2;\n   epo_1_seg_2--&gt;epo_1_seg_2_prms;\n   epo_1_seg_2_prms--&gt;epo_1_seg_2_freq;\n   epo_1_seg_2_prms--&gt;epo_1_seg_2_n_cyc;\n   epo_1_seg_2_prms--&gt;epo_1_seg_2_ph_offset_r2pi;\n   epo_1_seg_2_prms--&gt;epo_1_seg_2_ph_offset_t;\n   epo_1_seg_2--&gt;epo_1_seg_2_ops;\n   epo_1_seg_2_ops--&gt;epo_1_seg_2_1;\n   epo_1_seg_2_ops--&gt;epo_1_seg_2_2;\n   epo_2--&gt;epo_2_prms;\n   epo_2_prms--&gt;epo_2_Fs;\n   epo_2_prms--&gt;epo_2_L;\n   epo_2_prms--&gt;epo_2_T;\n   epo_2_prms--&gt;epo_2_offset_pts;\n   epo_2_prms--&gt;epo_2_offset_t;\n   epo_2--&gt;epo_2_ops;\n   epo_2_ops--&gt;epo_2_seg_1;\n   epo_2_seg_1--&gt;epo_2_seg_1_prms;\n   epo_2_seg_1_prms--&gt;epo_2_seg_1_freq;\n   epo_2_seg_1_prms--&gt;epo_2_seg_1_n_cyc;\n   epo_2_seg_1_prms--&gt;epo_2_seg_1_ph_offset_r2pi;\n   epo_2_seg_1_prms--&gt;epo_2_seg_1_ph_offset_t;\n   epo_2_seg_1--&gt;epo_2_seg_1_ops;\n   epo_2_seg_1_ops--&gt;epo_2_seg_1_1;\n   epo_2_seg_1_ops--&gt;epo_2_seg_1_2;\n   epo_2_ops--&gt;epo_2_seg_2;\n   epo_2_seg_2--&gt;epo_2_seg_2_prms;\n   epo_2_seg_2_prms--&gt;epo_2_seg_2_freq;\n   epo_2_seg_2_prms--&gt;epo_2_seg_2_n_cyc;\n   epo_2_seg_2_prms--&gt;epo_2_seg_2_ph_offset_r2pi;\n   epo_2_seg_2_prms--&gt;epo_2_seg_2_ph_offset_t;\n   epo_2_seg_2--&gt;epo_2_seg_2_ops;\n   epo_2_seg_2_ops--&gt;epo_2_seg_2_1;\n   epo_2_seg_2_ops--&gt;epo_2_seg_2_2;"
  },
  {
    "objectID": "content/posts/xpost_template3/index.html",
    "href": "content/posts/xpost_template3/index.html",
    "title": "title",
    "section": "",
    "text": "User Question:\n\n\nChatGPT Answer:"
  },
  {
    "objectID": "content/posts/neurophysiol_def_bot/index.html",
    "href": "content/posts/neurophysiol_def_bot/index.html",
    "title": "Denotation & Connotation of the term Neurophysiology",
    "section": "",
    "text": "User Question:\n\nDefine the denotation and connotations of the term, neurophysiology.\n\nChatGPT Answer:\n\nNeurophysiology is a branch of physiology and neuroscience that studies the functioning of the nervous system. To break this down in terms of denotation and connotations:\nDenotation (Literal Meaning):\nNeurophysiology is a scientific discipline focused on understanding how the nervous system functions. This includes studying the electrical and biochemical processes that occur in neurons (nerve cells) and neural circuits. The field encompasses a range of topics, from how neurons communicate with each other to how these processes result in motor functions, sensory perceptions, and cognitive abilities. Neurophysiologists use various techniques, such as electrophysiological recordings (like EEG and single neuron recording), to study the nervous system in both healthy and diseased states.\nConnotations (Associated Meanings and Implications):\n\nComplexity and Sophistication: Neurophysiology is often associated with the complexity of the brain and nervous system, one of the most intricate and sophisticated systems in the human body.\nCutting-Edge Science: The field is viewed as highly advanced and at the forefront of scientific research, particularly in understanding brain function and treating neurological disorders.\nInterdisciplinary Nature: Neurophysiology is inherently interdisciplinary, intersecting with fields like biology, psychology, medicine, and even engineering (in the context of developing neurological devices and interfaces).\nMedical and Health Implications: There’s a strong association with medical applications, particularly in diagnosing and treating neurological disorders such as epilepsy, Alzheimer’s disease, and Parkinson’s disease.\nTechnological Innovation: The field is often linked with technological advancements, especially in medical imaging and neuroimaging techniques like MRI and PET scans, which are crucial for studying brain function.\nEthical and Philosophical Questions: Neurophysiology can evoke discussions about deeper ethical and philosophical issues, such as the nature of consciousness, free will, and the mind-body connection.\n\nIn summary, while the denotation of neurophysiology refers to its scientific study of the nervous system, its connotations bring in aspects of complexity, interdisciplinary research, medical relevance, technological innovation, and deeper philosophical inquiries."
  },
  {
    "objectID": "content/posts/open_sci_github_intro/index.html",
    "href": "content/posts/open_sci_github_intro/index.html",
    "title": "Introduction to GitHub for Open Science",
    "section": "",
    "text": "Open Science With GitHub: An Introduction"
  },
  {
    "objectID": "content/posts/open_sci_github_intro/index.html#overview",
    "href": "content/posts/open_sci_github_intro/index.html#overview",
    "title": "Introduction to GitHub for Open Science",
    "section": "Overview",
    "text": "Overview\nMuch of open science requires some technical knowledge that many novices find to be initially burdensome and confusing. Open source analysis tools are usually a work in progress. Documentation for these tools, if present at all, will be incomplete or out of date. The purpose of this slideshow is to explore concepts that will enable team coordination on software usage and code development projects. The hope is that users will be able to find the information that they need from development notes and communication between code authors. In the long-term, notes and comments about the intended function, rationale, and usage of code will be useful for outsiders but also for the project organizers and code developers themselves."
  },
  {
    "objectID": "content/posts/interest_survey/index.html",
    "href": "content/posts/interest_survey/index.html",
    "title": "Initial Survey",
    "section": "",
    "text": "Please start the semester by responding to this survey. The goal of this activity is to begin to identify personal priorities and objectives and to think critically about your immediate and short-term goals in this course in relation to your long-term plans."
  },
  {
    "objectID": "content/posts/interest_survey/index.html#immediate-priorities",
    "href": "content/posts/interest_survey/index.html#immediate-priorities",
    "title": "Initial Survey",
    "section": "Immediate Priorities",
    "text": "Immediate Priorities\n\nEnvisioning Your Learning Journey:\nReflect on the cognitive and behavioral neuroscience concepts and knowledge areas you find most compelling. How would you like to integrate these into your coursework this semester to create a personalized learning journey?\nResearch Objectives:\nConsidering the research techniques and methodologies covered in this course, what specific research skills do you aim to develop this semester, and how do they align with your academic interests?\nAdditional Aspirations:\nBeyond the structured curriculum, what additional personal or professional goals would you like to set for yourself this semester, and how might these enhance your experience in the field of neuroscience?\nLong-Term Vision:\nCan you outline your provisional 1-, 3-, and 5-year goals related to your future career? How have these goals evolved since the last time you considered them, and how do they inform your current academic trajectory?\nInstructor’s Role:\nWhat specific support or resources from me, as your instructor, would be most beneficial in helping you achieve your academic and research goals this semester?\nAnticipated Challenges:\nWhat concerns or challenges do you anticipate facing next year in your endeavors, and how might you proactively address them?\nOvercoming Obstacles:\nAre there any particular worries you have about this upcoming semester that you would like to share, and what steps can I take to support you in overcoming these hurdles?\n\nThink strategically about your long-term education and research priorities, and set goals that are not only focused on immediate outcomes but also aligned with long-term academic and/or career aspirations. Moreover, these questions are an invitation for you to consider and articulate the role they would like me, as your course instructor, to play in your educational journey, fostering a collaborative learning environment for you and your classmates."
  },
  {
    "objectID": "content/posts/use_rsync_on_hpg/index.html",
    "href": "content/posts/use_rsync_on_hpg/index.html",
    "title": "Post template",
    "section": "",
    "text": "A better way is to copy all the files from the “psy4911/share” folder to your HiPerGator (HPG) folder. The rsync command for moving files between directories on HPG is described here. Copying_files_between_directories with rsync You will want to go to the shared folder on HPG first and open a terminal (see button outlined green in the schreenshot below). \nThen if you copy and paste these commands into terminal it will do the work for you: rsync -av /blue/psy4911/share/ket_ephys/ket_annot /blue/psy4911/yourusername/ket_ephys/ rsync -av /blue/psy4911/share/ket_ephys/ket_annot_segs /blue/psy4911/yourusername/ket_ephys/ rsync -av /blue/psy4911/share/ket_ephys/hi-ket /blue/psy4911/yourusername/ket_ephys/\nFor the files in the hi-ket folder there’s another script (and a package named NEO ) that’s required to convert them from .plx files to .fif files.\nRequired python packages: - NEO - NEO repo - NEO documentation - MNE - MNE Tutorial: importing data from NEO\nCode for the file conversion:\nThe main thing is that it takes 15 minutes per file on hipergator (HPG) when it’s set up like a laptop computer. When you configure HPG to run your jupter notebook in high-performance mode, it takes only a minute or two per file. So, what would take 5 hours for 20 files, ends up taking only a half hour.\nAn even bigger savings comes when doing machine learning / AI with deeplabcut on HPG."
  },
  {
    "objectID": "content/posts/xpost_template/discussion_papers/index.html",
    "href": "content/posts/xpost_template/discussion_papers/index.html",
    "title": "RPM",
    "section": "",
    "text": "[Project based learning](Keiler, L. S. (2018). Teachers’ roles and identities in student-centered classrooms. International journal of STEM education, 5, 1-20.0"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html",
    "title": "Open Neuro",
    "section": "",
    "text": "R for data science\nGGplot2\n\n\n\n\n\nPython data science handbook\nPython for data analysis, 3rd ed.\n\n\n\n\n\nR Tidymodels"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#books",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#books",
    "title": "Open Neuro",
    "section": "",
    "text": "R for data science\nGGplot2\n\n\n\n\n\nPython data science handbook\nPython for data analysis, 3rd ed.\n\n\n\n\n\nR Tidymodels"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#courses",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#courses",
    "title": "Open Neuro",
    "section": "Courses",
    "text": "Courses\n\nPython ML from scratch"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#skills",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#skills",
    "title": "Open Neuro",
    "section": "Skills",
    "text": "Skills\n\ntables/dataframe\ndata manipulation\ndata visualization"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#data-concepts",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#data-concepts",
    "title": "Open Neuro",
    "section": "Data Concepts",
    "text": "Data Concepts\n\ntidy data\ndata types: lists, arrays, dataframes, matrices\ndataytpes: int, float, string, boolean\ndata structures: series (1d), dataframe (2d), panel (3d)\ndata objects: series, dataframe, panel\ndata manipulation: indexing, slicing, filtering, sorting, grouping, joining, reshaping\ndata visualization: line plots, bar plots, histograms, scatter plots, box plots, heatmaps, subplots\ntidy data: each variable is a column, each observation is a row, each type of observational unit is a table\ndata types: lists, arrays, dataframes, matrices"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#functions-and-patterns",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#functions-and-patterns",
    "title": "Open Neuro",
    "section": "Functions and Patterns",
    "text": "Functions and Patterns\n\nfunctions: map, apply, filter, reduce, groupby, join, melt, pivot, transpose, stack, unstack, pivot_table, crosstab, merge, concat, append, sort, sort_values, sort_index, sortlevel,\ngrammar of graphics\nunit tests\ndata pipelines"
  },
  {
    "objectID": "content/posts/meeting_documentation/index.html",
    "href": "content/posts/meeting_documentation/index.html",
    "title": "Meeting Documentation Table",
    "section": "",
    "text": "Meeting types, roles, and responsibilities\n\n\n\n\n\n\n\n\n\n\nActivity\nTitle (for docs)\nOrganizer\nNote Taker\nSend Agenda/ Paper\nPublish Notes/Presentation\n\n\n\n\n1:1\n&lt;your name&gt;\nTeam member\nTeam member\n24 hrs before\n24 hrs after\n\n\n2:1\n&lt;your name&gt;\nJunior team member\nJunior team member\n24 hrs before\n24 hrs after\n\n\nClass Meeting: Literature discusssion\nClass meeting: Literature discussion\npresenter\n\n1 week before\n24 hrs after\n\n\nClass Meeting: Skills Session\nClass meeting: Tech\npresenter\n\n\n24 hrs after\n\n\nClass Meeting: Research\nClass meeting: &lt;your name&gt;&lt;date&gt;: Research\npresenter\npresenter\n\n24 hrs after\n\n\nSupervisory\nSupervisory\n&lt;your name&gt;&lt;date&gt;\npresenter\npresenter\n1 week before\n24 hrs after\n\n\nOther meeting\n&lt;meeting name&gt;&lt;date&gt;\nSenior team member\nJunior team member\n1 week before\n24 hrs after\n\n\n\n\n\n\n\n\nEach meeting has an organizer, who posts and emails the agenda. Most meetings have a note taker.\n\nCommunicate the agenda in advance.\n\nRationale: ensure everyone is fully prepared for the meeting. Meetings should be used for things that are more complex and nuanced than those that can be dealt with over email.\n\nAgenda content\n\nAgenda: : a numbered list of items or questions to discuss, each one no more than one line.\nShort explanatory notes can be later on in the document, if required.\n\nPosting the agenda\n\nCreating agenda for a new meeting or series\n\nCreate\n\nConverting a one-off meeting to a series\n\nCreate\n\n\nSending the agenda\n\nCreate an email with subject: “Agenda: ⟨title from Table 1⟩, ⟨date⟩”\nCopy the contents of the OneDrive Doc into the text of an email.\nAt the bottom, paste the URL of the agenda on OneDrive Doc (even if you have sent out this URL before).\nSend to all participants.\nPlease email all participants any later updates to the agenda.\n\n\n\n\n\n\nEdit the Agenda Google Doc to include minutes directly underneath individual agenda items.\n\nMinutes content\n\nRecord any decisions made in the meeting.\nAction items. For any actions discussed that need execution by meeting participants, put “ACTION: ⟨responsible person’s name⟩: ⟨action to be taken⟩” with “ACTION:” in bold and all caps. This includes any actions that need to be taken by Michael or other faculty.\nUsually it is unnecessary to take detailed notes, outside the categories of (i) records of decision and (ii) action items.\n\n\nSending the minutes:\n\nAs soon as possible after the meeting (within 24 hours), copy the contents of the agenda with notes into the text of an email and send it to all participants with the URL.\nCopy the notes into your lab notebook for a durable record."
  },
  {
    "objectID": "content/posts/meeting_documentation/index.html#overview-of-meeting-notes",
    "href": "content/posts/meeting_documentation/index.html#overview-of-meeting-notes",
    "title": "Meeting Documentation Table",
    "section": "",
    "text": "Meeting types, roles, and responsibilities\n\n\n\n\n\n\n\n\n\n\nActivity\nTitle (for docs)\nOrganizer\nNote Taker\nSend Agenda/ Paper\nPublish Notes/Presentation\n\n\n\n\n1:1\n&lt;your name&gt;\nTeam member\nTeam member\n24 hrs before\n24 hrs after\n\n\n2:1\n&lt;your name&gt;\nJunior team member\nJunior team member\n24 hrs before\n24 hrs after\n\n\nClass Meeting: Literature discusssion\nClass meeting: Literature discussion\npresenter\n\n1 week before\n24 hrs after\n\n\nClass Meeting: Skills Session\nClass meeting: Tech\npresenter\n\n\n24 hrs after\n\n\nClass Meeting: Research\nClass meeting: &lt;your name&gt;&lt;date&gt;: Research\npresenter\npresenter\n\n24 hrs after\n\n\nSupervisory\nSupervisory\n&lt;your name&gt;&lt;date&gt;\npresenter\npresenter\n1 week before\n24 hrs after\n\n\nOther meeting\n&lt;meeting name&gt;&lt;date&gt;\nSenior team member\nJunior team member\n1 week before\n24 hrs after\n\n\n\n\n\n\n\n\nEach meeting has an organizer, who posts and emails the agenda. Most meetings have a note taker.\n\nCommunicate the agenda in advance.\n\nRationale: ensure everyone is fully prepared for the meeting. Meetings should be used for things that are more complex and nuanced than those that can be dealt with over email.\n\nAgenda content\n\nAgenda: : a numbered list of items or questions to discuss, each one no more than one line.\nShort explanatory notes can be later on in the document, if required.\n\nPosting the agenda\n\nCreating agenda for a new meeting or series\n\nCreate\n\nConverting a one-off meeting to a series\n\nCreate\n\n\nSending the agenda\n\nCreate an email with subject: “Agenda: ⟨title from Table 1⟩, ⟨date⟩”\nCopy the contents of the OneDrive Doc into the text of an email.\nAt the bottom, paste the URL of the agenda on OneDrive Doc (even if you have sent out this URL before).\nSend to all participants.\nPlease email all participants any later updates to the agenda.\n\n\n\n\n\n\nEdit the Agenda Google Doc to include minutes directly underneath individual agenda items.\n\nMinutes content\n\nRecord any decisions made in the meeting.\nAction items. For any actions discussed that need execution by meeting participants, put “ACTION: ⟨responsible person’s name⟩: ⟨action to be taken⟩” with “ACTION:” in bold and all caps. This includes any actions that need to be taken by Michael or other faculty.\nUsually it is unnecessary to take detailed notes, outside the categories of (i) records of decision and (ii) action items.\n\n\nSending the minutes:\n\nAs soon as possible after the meeting (within 24 hours), copy the contents of the agenda with notes into the text of an email and send it to all participants with the URL.\nCopy the notes into your lab notebook for a durable record."
  },
  {
    "objectID": "content/github.html",
    "href": "content/github.html",
    "title": "Open Science with GitHub",
    "section": "",
    "text": "MNE-Tools Organization\nDeepLabCut Organization"
  },
  {
    "objectID": "content/meeting-notes/index.html",
    "href": "content/meeting-notes/index.html",
    "title": "Meeting template",
    "section": "",
    "text": "This is an example template for a new post. You can use it as a starting point for your own posts."
  },
  {
    "objectID": "content/meeting-notes/index.html#meeting-notes",
    "href": "content/meeting-notes/index.html#meeting-notes",
    "title": "Meeting template",
    "section": "Meeting notes",
    "text": "Meeting notes\n\nto be discussed\nAgenda for the meeting.\n\ntodo\ntodo\n\n\n\naccomplishments for the week\nList completed activities and notable accomplishments\n\nWhat is working…\nWhat is the current situation…\nWhat is not working…\n\n\n\npriorities for next week\n\nFinish HPG analysis, add to presentation\nMake changes to presentation based of lab meeting feedback and practice presentation\nFinish touching up manuscript draft\n\n\n\nchallenges and roadblocks\nDescribe potential challenges that have impeded or may impede your intended tasks and goals.\n\nMost of batch analysis is contingent on the job scheduler and is taking time\nI’ve had some issues with methylation adjustment and resulting files being corrupted which is pushing me back. Correcting this now\n\n\n\nLessons learned and opportunities for improvement\nList any area that might benefit from improvement within our control; problems you are trying to solve; lessons recently learned or relearned.\n\n\nLiterature\nInclude an interesting paper since the last meeting and a brief summary of why you chose this paper\n\n\nOther activities\nList other activities that are related to your work but are outside of research that you accomplished this week. This will help you appreciate and track all that you do.\n\n\nUpcoming deadlines/date and location of next meeting\n\nInclude the date and location of our next meeting so we can make sure we’re on the same calendar.*"
  },
  {
    "objectID": "content/meeting-notes/index.html#todo-list",
    "href": "content/meeting-notes/index.html#todo-list",
    "title": "Meeting template",
    "section": "TODO list",
    "text": "TODO list\n\ntodo\ntodo\ntodo\ntodo"
  },
  {
    "objectID": "content/links.html",
    "href": "content/links.html",
    "title": "Useful Links",
    "section": "",
    "text": "Models of Dynamical Systems\n\nMesoscopic Brain Dynamics\nSystem Dynamics Interactive Simulations\nKuramoto Model: Weakly Coupled Oscillators\n“Scale-free” Dynamics and Complexity\n1/f Noise\n\n\n\nFree Books for Python or R\n\nhttps://wesmckinney.com/book/\nhttps://r4ds.hadley.nz/\nhttps://jakevdp.github.io/PythonDataScienceHandbook/\nhttps://ggplot2-book.org/\nhttps://crumplab.com/Books.html\nhttps://github.com/christophergandrud/Rep-Res-Book\nhttps://merely-useful.tech/py-rse/\nhttps://merely-useful.tech/r-rse/\n\n\nData Science Courses\n\nhttps://merely-useful.tech/novice-r/\nhttps://github.com/merely-useful/novice-py/\nhttps://github.com/merely-useful/py-rse\n\n\n\nOpen Science\nStarting points for learning about accessibility\n\nhttps://quarto.org/\nhttps://voltrondata.com/labs\nhttps://carpentries.org/\nhttps://www.cos.io/products/osf\nhttps://ropensci.org\nhttps://posit.co/products/enterprise/academy/\nhttps://www.datacamp.com\n\n\n\nShared Docs with links to more information:\n\nhttps://github.com/asoplata/open-science-resources\nhttps://github.com/asoplata/open-computational-neuroscience-resources\n\n\n\nOpen Science Pre-publication Sites:\n\nhttps://neurolibre.org\nhttps://psyarxiv.com\nhttps://osf.io/preprints/\nhttps://arxiv.org\nCarpentries Tutorial: Introduction to Reproducible Publications with RStudio\n\n\n\nInteresting links\n\nTwo-minute Neuroscience: ketamine\n\n\n\n\nNeuroscience Information\n\nNeurodata Without Borders\nBrain Imaging Data Structure (BIDS)\nCarpentries: Working with MRI Data in Python\nCarpentries: Functional Neuroimaging Analysis in Python\nInternational Conference on Neuroinformatics (ICNF)\n\nICNF: Using Training Resources\nICNF: tutorial search\n\nNeuroStars\nNeuroHack Academy\nNeuroMatch Academy\nConcepts in Cognitive: Ontological/Taxonomy",
    "crumbs": [
      "Useful Links"
    ]
  },
  {
    "objectID": "content/miso.html",
    "href": "content/miso.html",
    "title": "Misophonia Project",
    "section": "",
    "text": "Also, known as selective sound sensitivity syndrome or sound-rage, misophonia is a disorder in which certain sounds trigger emotional or physiological responses that some might perceive as unreasonable given the circumstance. Those who have misophonia might describe it as when a sound “drives you crazy.” Their reactions can range from anger and annoyance to panic and the need to flee.\n\nMisophonia on Wikipedia\nWard, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., Traiser, C., … & Keil, A. (2022). The Relationship Between Self-Reported Misophonia Symptoms and Auditory Aversive Generalization Leaning: A Preliminary Report. Frontiers in Neuroscience, 16, 899476. https://doi.org/10.3389/fnins.2022.899476\nFarkas, A. H., Ward, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., … & Keil, A. (2023). Auditory Aversive Generalization Learning Prompts Threat-Specific Changes in Alpha-Band Activity. bioRxiv, 2023-12. https://doi.org/10.1101/2023.12.04.569971\nAccepted Pre-registration: Ward, R., Keil, A., Pouliot, J., Mears, R. P., Chiasson, P., & McIlvanie, S. (2021, September 27). Psychophysiological mechanisms underlying aversive conditioning in Misophonia.https://doi.org/10.17605/OSF.IO/E26AD\nMisophonia: Zotero Refs\n\n\n\nASMR (Autonomous sensory meridian response) is a tingling sensation that typically begins on the scalp and moves down the back of the neck and upper spine. A pleasant form of paresthesia, it has been compared with auditory-tactile synesthesia and may overlap with frisson.\n\n\n\n\nBrugge, J. F., Nourski, K. V., Oya, H., Reale, R. A., Kawasaki, H., Steinschneider, M., & Howard III, M. A. (2009). Coding of repetitive transients by auditory cortex on Heschl’s gyrus. Journal of neurophysiology, 102(4), 2358-2374. https://doi.org/10.1152/jn.91346.2008\nPopov, T., Oostenveld, R., & Schoffelen, J. M. (2018). FieldTrip made easy: an analysis protocol for group analysis of the auditory steady state brain response in time, frequency, and space. Frontiers in neuroscience, 12, 711.https://doi.org/10.3389/fnins.2018.00711\nPantev, C., Roberts, L. E., Elbert, T., Roβ, B., & Wienbruch, C. (1996). Tonotopic organization of the sources of human auditory steady-state responses. Hearing research, 101(1-2), 62-74.\nParker, D. A., Hamm, J. P., McDowell, J. E., Keedy, S. K., Gershon, E. S., Ivleva, E. I., … & Clementz, B. A. (2019). Auditory steady-state EEG response across the schizo-bipolar spectrum. Schizophrenia research, 209, 218-226. https://doi.org/10.1016/j.schres.2019.04.014\n\n\n\n\n\nMNE-Python is a Python package for MEG and EEG data analysis.\n\n\n\n\n\nMNE-BIDS is a Python package for converting data from the Brain Imaging Data Structure (BIDS) format to MNE-Python format.\nBIDS (Brain Imaging Data Structure) A simple and intuitive way to organize and describe your neuroimaging and behavioral data.\n\n\n\n\n\nMNE-BIDS-Pipeline is a full-flegded processing pipeline Python package for preprocessing MEG and EEG data.",
    "crumbs": [
      "Misophonia"
    ]
  },
  {
    "objectID": "content/miso.html#what-is-misophonia",
    "href": "content/miso.html#what-is-misophonia",
    "title": "Misophonia Project",
    "section": "",
    "text": "Also, known as selective sound sensitivity syndrome or sound-rage, misophonia is a disorder in which certain sounds trigger emotional or physiological responses that some might perceive as unreasonable given the circumstance. Those who have misophonia might describe it as when a sound “drives you crazy.” Their reactions can range from anger and annoyance to panic and the need to flee.\n\nMisophonia on Wikipedia\nWard, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., Traiser, C., … & Keil, A. (2022). The Relationship Between Self-Reported Misophonia Symptoms and Auditory Aversive Generalization Leaning: A Preliminary Report. Frontiers in Neuroscience, 16, 899476. https://doi.org/10.3389/fnins.2022.899476\nFarkas, A. H., Ward, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., … & Keil, A. (2023). Auditory Aversive Generalization Learning Prompts Threat-Specific Changes in Alpha-Band Activity. bioRxiv, 2023-12. https://doi.org/10.1101/2023.12.04.569971\nAccepted Pre-registration: Ward, R., Keil, A., Pouliot, J., Mears, R. P., Chiasson, P., & McIlvanie, S. (2021, September 27). Psychophysiological mechanisms underlying aversive conditioning in Misophonia.https://doi.org/10.17605/OSF.IO/E26AD\nMisophonia: Zotero Refs\n\n\n\nASMR (Autonomous sensory meridian response) is a tingling sensation that typically begins on the scalp and moves down the back of the neck and upper spine. A pleasant form of paresthesia, it has been compared with auditory-tactile synesthesia and may overlap with frisson.\n\n\n\n\nBrugge, J. F., Nourski, K. V., Oya, H., Reale, R. A., Kawasaki, H., Steinschneider, M., & Howard III, M. A. (2009). Coding of repetitive transients by auditory cortex on Heschl’s gyrus. Journal of neurophysiology, 102(4), 2358-2374. https://doi.org/10.1152/jn.91346.2008\nPopov, T., Oostenveld, R., & Schoffelen, J. M. (2018). FieldTrip made easy: an analysis protocol for group analysis of the auditory steady state brain response in time, frequency, and space. Frontiers in neuroscience, 12, 711.https://doi.org/10.3389/fnins.2018.00711\nPantev, C., Roberts, L. E., Elbert, T., Roβ, B., & Wienbruch, C. (1996). Tonotopic organization of the sources of human auditory steady-state responses. Hearing research, 101(1-2), 62-74.\nParker, D. A., Hamm, J. P., McDowell, J. E., Keedy, S. K., Gershon, E. S., Ivleva, E. I., … & Clementz, B. A. (2019). Auditory steady-state EEG response across the schizo-bipolar spectrum. Schizophrenia research, 209, 218-226. https://doi.org/10.1016/j.schres.2019.04.014\n\n\n\n\n\nMNE-Python is a Python package for MEG and EEG data analysis.\n\n\n\n\n\nMNE-BIDS is a Python package for converting data from the Brain Imaging Data Structure (BIDS) format to MNE-Python format.\nBIDS (Brain Imaging Data Structure) A simple and intuitive way to organize and describe your neuroimaging and behavioral data.\n\n\n\n\n\nMNE-BIDS-Pipeline is a full-flegded processing pipeline Python package for preprocessing MEG and EEG data.",
    "crumbs": [
      "Misophonia"
    ]
  },
  {
    "objectID": "content/code.html",
    "href": "content/code.html",
    "title": "Working with Code",
    "section": "",
    "text": "We are interested in doing open science because we’d like to return the favor back to the scientific community as open science has been helpful to us.\n\nx &lt;- c(5, 15, 25, 35, 45, 55)\ny &lt;- c(5, 20, 14, 32, 22, 38)\nlm(x ~ y)\n\n\nCall:\nlm(formula = x ~ y)\n\nCoefficients:\n(Intercept)            y  \n      1.056        1.326",
    "crumbs": [
      "Code in your files"
    ]
  },
  {
    "objectID": "content/mpfc.html",
    "href": "content/mpfc.html",
    "title": "MPFC & Ketamine Project",
    "section": "",
    "text": "mPFC-ketamine Zotero Refs\n\n\n\n\nNath, T., Mathis, A., Chen, A. C., Patel, A., Bethge, M., & Mathis, M. W. (2019). Using DeepLabCut for 3D markerless pose estimation across species and behaviors. Nature protocols, 14(7), 2152-2176. https://doi.org/10.1038/s41596-019-0176-0\nMathis, A., Schneider, S., Lauer, J., & Mathis, M. W. (2020). A primer on motion capture with deep learning: principles, pitfalls, and perspectives. Neuron, 108(1), 44-65. https://doi.org/10.1016/j.neuron.2020.09.017\n\n\n\n\nDLC Course Links\nIntroduction to DeepLabCut for Non-Programmers\nAnnotation & Labeling keypoints with napari-deeplabcut",
    "crumbs": [
      "MPFC"
    ]
  },
  {
    "objectID": "content/mpfc.html#overview",
    "href": "content/mpfc.html#overview",
    "title": "MPFC & Ketamine Project",
    "section": "",
    "text": "mPFC-ketamine Zotero Refs\n\n\n\n\nNath, T., Mathis, A., Chen, A. C., Patel, A., Bethge, M., & Mathis, M. W. (2019). Using DeepLabCut for 3D markerless pose estimation across species and behaviors. Nature protocols, 14(7), 2152-2176. https://doi.org/10.1038/s41596-019-0176-0\nMathis, A., Schneider, S., Lauer, J., & Mathis, M. W. (2020). A primer on motion capture with deep learning: principles, pitfalls, and perspectives. Neuron, 108(1), 44-65. https://doi.org/10.1016/j.neuron.2020.09.017\n\n\n\n\nDLC Course Links\nIntroduction to DeepLabCut for Non-Programmers\nAnnotation & Labeling keypoints with napari-deeplabcut",
    "crumbs": [
      "MPFC"
    ]
  },
  {
    "objectID": "content/publishing.html",
    "href": "content/publishing.html",
    "title": "Publishing",
    "section": "",
    "text": "To get your Quarto webpage to show up with the url\nyou have a few steps."
  },
  {
    "objectID": "content/publishing.html#turn-on-github-pages-for-your-repo",
    "href": "content/publishing.html#turn-on-github-pages-for-your-repo",
    "title": "Publishing",
    "section": "Turn on GitHub Pages for your repo",
    "text": "Turn on GitHub Pages for your repo\n\nTurn on GitHub Pages under Settings &gt; Pages . You will set pages to be made from the gh-pages branch and the root directory.\nTurn on GitHub Actions under Settings &gt; Actions &gt; General\n\nThe GitHub Action will automatically recreate your website when you push to GitHub after you do the initial gh-pages set-up"
  },
  {
    "objectID": "content/publishing.html#do-your-first-publish-to-gh-pages",
    "href": "content/publishing.html#do-your-first-publish-to-gh-pages",
    "title": "Publishing",
    "section": "Do your first publish to gh-pages",
    "text": "Do your first publish to gh-pages\nThe first time you publish to gh-pages, you need to do so locally.\n\nOn your local computer, open a terminal window and cd to your repo directory. Here is what that cd command looks like for me. You command will look different because your local repo will be somewhere else on your computer.\n\ncd ~/Documents/GitHub/NOAA-quarto-simple\n\nPublish to the gh-pages. In the terminal type\n\nquarto publish gh-pages\nThis is going to render your webpage and then push the _site contents to the gh-pages branch."
  },
  {
    "objectID": "content/publishing.html#dont-like-using-gh-pages",
    "href": "content/publishing.html#dont-like-using-gh-pages",
    "title": "Publishing",
    "section": "Don’t like using gh-pages?",
    "text": "Don’t like using gh-pages?\nIn some cases, you don’t want your website on the gh-pages branch. For example, if you are creating releases and you want the website pages archived in that release, then you won’t want your website pages on the gh-pages branch.\nHere are the changes you need to make if you to avoid gh-pages branch.\n\nAt the top of _quarto.yml add the following:\n\nproject: \n  type: website\n  output-dir: docs\n\nOn GitHub under Settings &gt; Pages set pages to be made from the main branch and the docs directory.\nMake sure docs is not listed in .gitignore\nPublish the site the first time locally using quarto publish from the terminal\nChange the GitHub Action because you can’t use quarto publish gh-pages. You’ll need to push to the main branch yourself (in the GitHub Action)\n\non:\n  push:\n    branches: main\n\nname: Render and Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2 \n        \n      - name: Set up R (needed for Rmd)\n        uses: r-lib/actions/setup-r@v2\n\n      - name: Install packages (needed for Rmd)\n        run: Rscript -e 'install.packages(c(\"rmarkdown\", \"knitr\", \"jsonlite\"))'\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          # To install LaTeX to build PDF book \n          # tinytex: true \n          # uncomment below and fill to pin a version\n          # version: 0.9.600\n      \n      - name: Render Quarto Project\n        uses: quarto-dev/quarto-actions/render@v2\n        with:\n          to: html\n\n      - name: Set up Git\n        run: |\n          git config --local user.email \"actions@github.com\"\n          git config --local user.name \"GitHub Actions\"\n\n      - name: Commit all changes and push\n        run: |\n          git add -A && git commit -m 'Build site' || echo \"No changes to commit\"\n          git push origin || echo \"No changes to commit\""
  },
  {
    "objectID": "content/meeting-notes/index2.html",
    "href": "content/meeting-notes/index2.html",
    "title": "Meeting Notes",
    "section": "",
    "text": "Thurs (01/25/2024)\n\n\n\nConfirmed interest toward teams (GitHub ID: sub teams)\nIntroduced training plan\n\nDeveloping a Training Plan\n\nTrain like a scientist…\nBreak problem into pieces, isolate smallest parts, and cultivate capabilities. For developing specific skills, identify available resources, and then find out how to acquire technical knowledge and then practice procedures.\nWe discussed how we will use GitHub in the course and for open science.\n\n\n\n\nadd notes\npublish notes\nother business"
  },
  {
    "objectID": "content/meeting-notes/index2.html#summary-notes",
    "href": "content/meeting-notes/index2.html#summary-notes",
    "title": "Meeting Notes",
    "section": "",
    "text": "Confirmed interest toward teams (GitHub ID: sub teams)\nIntroduced training plan\n\nDeveloping a Training Plan\n\nTrain like a scientist…\nBreak problem into pieces, isolate smallest parts, and cultivate capabilities. For developing specific skills, identify available resources, and then find out how to acquire technical knowledge and then practice procedures.\nWe discussed how we will use GitHub in the course and for open science.\n\n\n\n\nadd notes\npublish notes\nother business"
  },
  {
    "objectID": "content/lab-information/lab-information-example-post/index.html",
    "href": "content/lab-information/lab-information-example-post/index.html",
    "title": "Example template",
    "section": "",
    "text": "This is an example template for a new post. You can use it as a starting point for your own posts."
  },
  {
    "objectID": "content/posts/use_ssh_mne/index.html",
    "href": "content/posts/use_ssh_mne/index.html",
    "title": "SSH to HPG3 and run MNE-BIDS-Pipeline",
    "section": "",
    "text": "Type the following command in the terminal:\nssh urgatoruser@hpg.rc.ufl.edu\nThen, follow the prompts to enter your password and Duo two-factor authentication.\nYour password will not be displayed as you type it. Then, your terminal should look like this:\nssh urgatoruser@hpg.rc.ufl.edu\nPassword: xxxxxxxx\nDuo two-factor login for urgatoruser@ufl.edu\n\nEnter a passcode or select one of the following options:\n\n 1. Duo Push to XXX-XXX-1809\n 2. Phone call to XXX-XXX-1809\n\nPasscode or option (1-2): 1\nWorks through the UF Single-sign on similar to for Canvas and gatormail.\n\n\nsrun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=2 --mem=2gb -t 90 --pty bash -i\n`[mygatoruser@login1 ~]$ srun –pty -p hpg2-compute -n 1 -N 1 -t 90 –mem=2gb /bin/bash’\n\n\n\nsrun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=4 --mem=28gb -t 60 --pty bash -i\nsrun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=4 --mem=28gb -t 60 --pty bash -i\nsrun: job 4572441 queued and waiting for resources\nsrun: job 4572441 has been allocated resources.\nNow you are on the compute node. You can check the hostname and the node list with the following commands:\necho \"Hello from $(hostname)\"\nHello from c0711a-s6.ufhpc\necho $SLURM_JOB_NODELIST\nc0711a-s6"
  },
  {
    "objectID": "content/posts/use_ssh_mne/index.html#a-single-node-2-cpu-core-job-with-2gb-of-ram-for-90-minutes-can-be-started-with-the-following-command",
    "href": "content/posts/use_ssh_mne/index.html#a-single-node-2-cpu-core-job-with-2gb-of-ram-for-90-minutes-can-be-started-with-the-following-command",
    "title": "SSH to HPG3 and run MNE-BIDS-Pipeline",
    "section": "",
    "text": "srun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=2 --mem=2gb -t 90 --pty bash -i\n`[mygatoruser@login1 ~]$ srun –pty -p hpg2-compute -n 1 -N 1 -t 90 –mem=2gb /bin/bash’"
  },
  {
    "objectID": "content/posts/use_ssh_mne/index.html#a-single-node-4-cpu-core-job-with-28gb-of-ram-for-120-minutes-can-be-started-with-the-following-command",
    "href": "content/posts/use_ssh_mne/index.html#a-single-node-4-cpu-core-job-with-28gb-of-ram-for-120-minutes-can-be-started-with-the-following-command",
    "title": "SSH to HPG3 and run MNE-BIDS-Pipeline",
    "section": "",
    "text": "srun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=4 --mem=28gb -t 60 --pty bash -i\nsrun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=4 --mem=28gb -t 60 --pty bash -i\nsrun: job 4572441 queued and waiting for resources\nsrun: job 4572441 has been allocated resources.\nNow you are on the compute node. You can check the hostname and the node list with the following commands:\necho \"Hello from $(hostname)\"\nHello from c0711a-s6.ufhpc\necho $SLURM_JOB_NODELIST\nc0711a-s6"
  },
  {
    "objectID": "content/posts/use_ssh_mne/index.html#random-tips",
    "href": "content/posts/use_ssh_mne/index.html#random-tips",
    "title": "SSH to HPG3 and run MNE-BIDS-Pipeline",
    "section": "Random Tips:",
    "text": "Random Tips:\nCreate a symbolic link to your group storage directory on Blue drive:\nln -s /blue/psb4934/ blue_psb4934\nUsing OpenOn Demand for file management\nTroubleshooting HPG3 Open OnDemand\nUsing rsync to copy/move files on HPG3\nmacOS Development Environment: iTerm2, oh-my-zsh, and VS Code"
  },
  {
    "objectID": "content/posts/DLC_methods_spring_2023/index.html",
    "href": "content/posts/DLC_methods_spring_2023/index.html",
    "title": "DLC methods",
    "section": "",
    "text": "How to write a DeepLabCut Methods Section\nconfig.yaml file"
  },
  {
    "objectID": "content/posts/DLC_methods_spring_2023/index.html#methods-items",
    "href": "content/posts/DLC_methods_spring_2023/index.html#methods-items",
    "title": "DLC methods",
    "section": "Methods items",
    "text": "Methods items\nFor body part tracking we used DeepLabCut (version 2.X.X) [Mathis et al, 2018, Nath et al, 2019]. - DLC v.2.2.6 ?\nSpecifically, we labeled X number of frames taken from X videos/animals (then X% was used for training (default is 95%).\n\n30 frames\n3 animals\n3 videos\n28 frames were used for training, i.e., the the DLC default proportion 95%\n\nWe used a X-based neural network (i.e., X = ResNet-50) with default parameters for 500,000 training iterations. [see citations below]\n\nNOTE: I’m not certain what X refers to for X-based; X = ResNet-50\nX?: 500,000 training iterations\n\nWe validated with X number of shuffles,\n\n1 shuffle\n\nand found the test error was: X pixels, train: X pixels (image size was X by X).\n\ntest error was 37.38 pixels\ntraining error was 1.73 pixels\nimage size was 720 by X 480 pixels\n\nWe then used a p-cutoff of X (i.e. 0.9) to condition the X,Y coordinates for future analysis.\n\nvery consevative p-cutoff of 0.6 for X,Y coordinates for future analysis\n\nThis network was then used to analyze eight videos from similar experimental settings.\n\nReferences\nInsafutdinov, E., Pishchulin, L., Andres, B., Andriluka, M. & Schiele, B. DeeperCut: A deeper, stronger, and faster multi-person pose estimation model. In European Conference on Computer Vision, 34–50 (Springer, 2016).\nHe, K., Zhang, X., Ren, S. & Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, 770–778 (2016). URL https://arxiv.org/abs/ 1512.03385."
  },
  {
    "objectID": "content/posts/test_post/index.html",
    "href": "content/posts/test_post/index.html",
    "title": "Post template",
    "section": "",
    "text": "This is a test post."
  },
  {
    "objectID": "content/posts/training_plan_dev/index.html",
    "href": "content/posts/training_plan_dev/index.html",
    "title": "Developing a training plan",
    "section": "",
    "text": "1. Aims/Goals - What do you want to learn?\n2. Resources - What resources are available to you?\n3. Approaches - What approaches are available to you?\n4. Methods - What methods are available to you?\n5. Steps - What steps do you take to learn?\n6. Implementation - Who will collaborate and facilitate?\n7. Roles and Responsibilities - Who will do what?\n7. Assessment - How will you know you are learning?\n8. Evaluation - How will you know you have learned?"
  },
  {
    "objectID": "content/posts/training_plan_dev/index.html#essential-components-of-a-training-plan",
    "href": "content/posts/training_plan_dev/index.html#essential-components-of-a-training-plan",
    "title": "Developing a training plan",
    "section": "",
    "text": "1. Aims/Goals - What do you want to learn?\n2. Resources - What resources are available to you?\n3. Approaches - What approaches are available to you?\n4. Methods - What methods are available to you?\n5. Steps - What steps do you take to learn?\n6. Implementation - Who will collaborate and facilitate?\n7. Roles and Responsibilities - Who will do what?\n7. Assessment - How will you know you are learning?\n8. Evaluation - How will you know you have learned?"
  },
  {
    "objectID": "content/posts/training_plan_dev/index.html#meta-learning",
    "href": "content/posts/training_plan_dev/index.html#meta-learning",
    "title": "Developing a training plan",
    "section": "Meta-learning",
    "text": "Meta-learning\n\n\n\n\n\n\n\ngraph TD;\n    A[Define Aims/Goals] --&gt; B[Identify Resources]\n    B --&gt; C[Inquire about approaches]\n    C --&gt; D[Iterrogate methods]\n    D --&gt; E[Take step]\n    E --&gt; F[Recursively repeat...]--&gt;A\n\n\n\n\n\n\n\n\n\n\nLearn as a scientist\n\nHow do I learn how to do … ?\n\n\n\nCultivating capabilities\n\nHow do I find out what I need to learn to do … ?\n\n\n\nAcquire specific knowledge/skills\n\nWhat initial steps do I take?"
  },
  {
    "objectID": "content/posts/training_plan_dev/index.html#open-science-approach-to-computational-reproducibility",
    "href": "content/posts/training_plan_dev/index.html#open-science-approach-to-computational-reproducibility",
    "title": "Developing a training plan",
    "section": "Open Science Approach to Computational Reproducibility",
    "text": "Open Science Approach to Computational Reproducibility\n\n\nSpecificity\n\n\n\n\n\ngraph TD;\n    A[coarse] -----&gt; B[granular]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngraph LR;\n    A[Abstract] ---&gt; |Representativeness &lt;/br&gt; &lt;/br&gt; &lt;/tab&gt; | B[Concrete]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing Environment\nWorkflow /  Pipeline\n\n\nRaw Data  & Code\nAnalysis Derivatives-derived variables-stats/figures\n\n\n\n\n\n\nComputing Environment\n\nlearn how computing works (computing abstractions, operating systems graphics hardware, applications/software, filesystems, etc.)\nlearn shell scripting for generalizing tasks across hardware/operating systems\n\n\n\nworkflow/pipeline\n\nreproducibility/open science\n\n\n\nraw data / code\n\nlearn how to use this\ndataframe concepts\n\n\n\nDerivatives\n\ndata wrangling in Python/R\nlearn how to graph in Python/R\nimplementation of intermediate steps\ninferential statistics\n\n\n\nanother graph\n\n\n\n\n\n%%{init: {'theme':'forest'}}%%\ngraph LR\n\n    subgraph DeepLabCut\n        direction BT\n        subgraph Training\n            s1--&gt;s2\n\n        end\n\n        subgraph Decoding\n            s3 --&gt; s1\n            \n        end\n\n        s2 --&gt;s3 \n       \n    end\n \n\n    subgraph ETHZ-INS/DLCAnalyzer\n        direction BT\n        s3 --&gt; s4\n        s5 --&gt; s6 \n        s6 --&gt; s4\n        \n        subgraph dlca[Derivative Variables &lt;/br&gt; Data Visualizations]\n          s4 --&gt; s5\n        end\n    end\n\n    subgraph Analysis\n       s6 --&gt;  s7{Inferential Stats}\n    end\n \n\n %% Notice that no text in shape are added here instead that is appended further down\n    \n\n    %% Comments after double percent signs\n\n     classDef green fill:#9f6,stroke:#333,stroke-width:0.5px;\n     classDef orange fill:#f96,stroke:#333,stroke-width:1px;\n     classDef white fill:#fff,stroke:#333,stroke-width:1px;\n     classDef sq stroke:#f66,stroke-width:1px;\n     classDef blue fill:#6699cc,stroke:#333,stroke-width:1px;\n     class sq,Analysis green\n     class ETHZ-INS/DLCAnalyzer orange\n     class Training,dlca white\n     class DeepLabCut white\n     class Decoding blue"
  },
  {
    "objectID": "content/posts/new_hpg3/index.html",
    "href": "content/posts/new_hpg3/index.html",
    "title": "Getting Started with UF Research Computing",
    "section": "",
    "text": "Course Registration\n\nIf you are in PSB4934: skip the next step.\nIf you’re not in PSB4934: Fill out PSY4911 form and complete 2 training topics i.e., required by Psychology:\n\nFERPA Basics\nMaintaining a Safe and Respectful Campus\n\n\n\n\nOrientation to High-Performance Computing on HiPerGator3 (HPG)\n\nGo to HiPerGator3 New User Training i.e.,req by UF RC\nComplete the required Coursera training\nGo to the UFRC Getting Started page\nBookmark the UFRC Help and Documentation page in your browser"
  },
  {
    "objectID": "content/rmarkdown.html",
    "href": "content/rmarkdown.html",
    "title": "R Markdown",
    "section": "",
    "text": "You can include R Markdown files in your project."
  },
  {
    "objectID": "content/rmarkdown.html#r-markdown",
    "href": "content/rmarkdown.html#r-markdown",
    "title": "R Markdown",
    "section": "R Markdown",
    "text": "R Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "content/rmarkdown.html#including-plots",
    "href": "content/rmarkdown.html#including-plots",
    "title": "R Markdown",
    "section": "Including Plots",
    "text": "Including Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot."
  },
  {
    "objectID": "content/rendering.html",
    "href": "content/rendering.html",
    "title": "Rendering",
    "section": "",
    "text": "The repo includes a GitHub Action that will render (build) the website automatically when you make changes to the files. It will be pushed to the gh-pages branch.\nBut when you are developing your content, you will want to render it locally."
  },
  {
    "objectID": "content/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "href": "content/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "title": "Rendering",
    "section": "Step 1. Make sure you have a recent RStudio",
    "text": "Step 1. Make sure you have a recent RStudio\nHave you updated RStudio since about August 2022? No? Then update to a newer version of RStudio. In general, you want to keep RStudio updated and it is required to have a recent version to use Quarto."
  },
  {
    "objectID": "content/rendering.html#step-2.-clone-and-create-rstudio-project",
    "href": "content/rendering.html#step-2.-clone-and-create-rstudio-project",
    "title": "Rendering",
    "section": "Step 2. Clone and create RStudio project",
    "text": "Step 2. Clone and create RStudio project\nFirst, clone the repo onto your local computer. How? You can click File &gt; New Project and then select “Version Control”. Paste in the url of the repository. That will clone the repo on to your local computer. When you make changes, you will need to push those up."
  },
  {
    "objectID": "content/rendering.html#step-3.-render-within-rstudio",
    "href": "content/rendering.html#step-3.-render-within-rstudio",
    "title": "Rendering",
    "section": "Step 3. Render within RStudio",
    "text": "Step 3. Render within RStudio\nRStudio will recognize that this is a Quarto project by the presence of the _quarto.yml file and will see the “Build” tab. Click the “Render website” button to render to the _site folder.\nPreviewing: You can either click index.html in the _site folder and specify “preview in browser” or set up RStudio to preview to the viewer panel. To do the latter, go to Tools &gt; Global Options &gt; R Markdown. Then select “Show output preview in: Viewer panel”."
  },
  {
    "objectID": "content/wiki.html",
    "href": "content/wiki.html",
    "title": "Open-Science-Wiki",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 10, 2023\n\n\nExample template\n\n\nRPM \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/wiki.html#lab-information",
    "href": "content/wiki.html#lab-information",
    "title": "Open-Science-Wiki",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 10, 2023\n\n\nExample template\n\n\nRPM \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/wiki.html#meeting-notes",
    "href": "content/wiki.html#meeting-notes",
    "title": "Open-Science-Wiki",
    "section": "Meeting Notes",
    "text": "Meeting Notes\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 25, 2024\n\n\nMeeting Notes\n\n\nCA \n\n\n\n\nOct 10, 2023\n\n\nMeeting template\n\n\nRPM \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/wiki.html#posts",
    "href": "content/wiki.html#posts",
    "title": "Open-Science-Wiki",
    "section": "Posts",
    "text": "Posts\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDLC methods\n\n\n\n\n\n\nRPM\n\n\nJan 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSFN poster link\n\n\n\n\n\n\nRPM\n\n\nJan 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPGSO 2023 poster link\n\n\n\n\n\n\nRPM\n\n\nJan 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDenotation & Connotation of the term Neurophysiology\n\n\n\nChatGPT\n\n\ndefinitions\n\n\n\n\n\n\n\nbot\n\n\nJan 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nInitial Survey\n\n\n\n\n\n\nRPM\n\n\nJan 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMeeting Documentation Table\n\n\n\n\n\n\nRPM\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDeveloping a training plan\n\n\n\n\n\n\nRPM\n\n\nDec 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSSH to HPG3 and run MNE-BIDS-Pipeline\n\n\n\n\n\n\nRPM\n\n\nAug 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPost template\n\n\n\n\n\n\nRPM\n\n\nMar 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with UF Research Computing\n\n\n\n\n\n\nRPM\n\n\nJan 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial on MNE-BIDS-Pipeline\n\n\n\n\n\n\nRPM\n\n\nJan 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to GitHub for Open Science\n\n\n\ncode\n\n\ndevelopment\n\n\norganization\n\n\nversion control\n\n\nslides\n\n\ntutorial\n\n\n\nIntroduction to Version control for doing open science\n\n\n\nR Mears\n\n\nJul 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPost template\n\n\n\n\n\n\nRPM\n\n\nJun 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRPM\n\n\n\n\n\n\nRPM\n\n\nOct 31, 2019\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\n\n\n\nChatGPT\n\n\n\n\n\n\n\nbot\n\n\nOct 31, 2019\n\n\n\n\n\n\n\n\nNo matching items"
  }
]
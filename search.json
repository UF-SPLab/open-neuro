[
  {
    "objectID": "content/mpfc.html",
    "href": "content/mpfc.html",
    "title": "MPFC & Ketamine Project",
    "section": "",
    "text": "mPFC-ketamine Zotero Refs\n\n\n\n\nNath, T., Mathis, A., Chen, A. C., Patel, A., Bethge, M., & Mathis, M. W. (2019). Using DeepLabCut for 3D markerless pose estimation across species and behaviors. Nature protocols, 14(7), 2152-2176. https://doi.org/10.1038/s41596-019-0176-0\nMathis, A., Schneider, S., Lauer, J., & Mathis, M. W. (2020). A primer on motion capture with deep learning: principles, pitfalls, and perspectives. Neuron, 108(1), 44-65. https://doi.org/10.1016/j.neuron.2020.09.017\n\nDeepLabCut\n\n\n\n\n\n\nSturman, O, von Ziegler, L, Schläppi, C et al.(2020). Deep learning-based behavioral analysis reaches human accuracy and is capable of outperforming commercial solutions. Neuropsychopharmacology 45, 1942–52 https://doi.org/10.1038/s41386-020-0776-y\n\nData from DLC (Python):wrangle/plot (R)\n\n\n\n\n\n\n\n\nDLC Course Links\nIntroduction to DeepLabCut for Non-Programmers\nAnnotation & Labeling keypoints with napari-deeplabcut\n\n\n\n\n\nhttps://www.mackenziemathislab.org/dlc-modelzoo\nSingle-frame analysis.\n\nThis just works. It’s a small-scale version of what happens on a large-scale with all the 2d frames from your videos.\n\n\n\n\n\nMost of the DeepLabCut (DLC) tutorials are offered with Google Colab a cloud computing environment with all the software dependencies pre-installed. It really is the best first step if you want to start to understand how DLC works and how to customize it for your needs. - Click on the “Open in Colab” link on this page - Video on DLC on Google Colab - Colab instructions on how to use your own videos\n\n\n\nDeepLabCut Worshop Materials\n\n\n\n\nUF Research Computing\nUFRC Training\n\n\n\n\n\n\nYouTube video on using DeepLabCut GUI (~3 min)\nInstalling Deeplabcut https://deeplabcut.github.io/DeepLabCut/docs/installation.html\nDLC User Guide https://deeplabcut.github.io/DeepLabCut/docs/standardDeepLabCut_UserGuide.html\nNapari GUI https://deeplabcut.github.io/DeepLabCut/docs/napariGUI.html\nSlightly outdated workshop https://github.com/DeepLabCut/DeepLabCut-Workshop-Materials\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {'theme':'forest'}}%%\n\ngraph LR\n\n    subgraph Analysis\n       s6 --&gt;  s7{Inferential Stats}\n    end\n \n    subgraph ETHZ-INS/DLCAnalyzer\n        s3 --&gt; s4[Data Wrangling &lt;/br&gt; Graphing]\n        s5 --&gt; s6[Data Wrangling]\n        s6 --&gt; s4\n        \n        subgraph dlca[&lt;/tab&gt; &lt;/br&gt; Derivative Variables / Data Visualizations]\n          s4 --&gt; s5[unsupervised&lt;/br&gt; classification&lt;/br&gt; and clustering]\n        end\n    end\n\n    subgraph DeepLabCut\n\n        subgraph Training\n            s1[add keypoints]--&gt;s2[run training]\n            s2 --&gt; s2a[analyze&lt;/br&gt; training]\n            s2a --&gt;s2\n\n        end\n\n        subgraph Decoding\n            s2a --&gt; s3a[add&lt;/br&gt; videos] \n            \n        end\n        \n         \n        s3a --&gt; s3[import data&lt;/br&gt;transform]\n       \n    end\n    \n    subgraph Read-in-Data[Raw Data]\n        s0[import video] --&gt; s1\n    end\n    \n %% Notice that no text in shape are added here instead that is appended further down\n    \n\n    %% Comments after double percent signs\n\n     classDef green fill:#9f6,stroke:#333,stroke-width:0.5px;\n     classDef orange fill:#f96,stroke:#333,stroke-width:1px;\n     classDef white fill:#fff,stroke:#333,stroke-width:1px;\n     classDef sq stroke:#f66,stroke-width:1px;\n     classDef blue fill:#6699cc,stroke:#333,stroke-width:1px;\n     classDef red fill:#D32737,stroke:#FFF,stroke-width:1.5px;\n     class sq,Analysis green\n     class ETHZ-INS/DLCAnalyzer orange\n     class Training,dlca,s0 white\n     class DeepLabCut white\n     class Decoding blue\n     class Read-in-Data red\n     \n\n\n\n\n\n\n\n\n on Github/ Workshop\n\n\nUnsupervised Clustering: (R) / (R Shiny)\n\n\n\n\n\n\n\n\n\n\n[ X ] Digitize behavior videos from analog\n[ X ] Cut, Segment, Name: Subject & Session\n[ X ] Extract behavior timestamp range\n[ X ] Select behavior videos for DLC training",
    "crumbs": [
      "MPFC"
    ]
  },
  {
    "objectID": "content/mpfc.html#overview",
    "href": "content/mpfc.html#overview",
    "title": "MPFC & Ketamine Project",
    "section": "",
    "text": "mPFC-ketamine Zotero Refs\n\n\n\n\nNath, T., Mathis, A., Chen, A. C., Patel, A., Bethge, M., & Mathis, M. W. (2019). Using DeepLabCut for 3D markerless pose estimation across species and behaviors. Nature protocols, 14(7), 2152-2176. https://doi.org/10.1038/s41596-019-0176-0\nMathis, A., Schneider, S., Lauer, J., & Mathis, M. W. (2020). A primer on motion capture with deep learning: principles, pitfalls, and perspectives. Neuron, 108(1), 44-65. https://doi.org/10.1016/j.neuron.2020.09.017\n\nDeepLabCut\n\n\n\n\n\n\nSturman, O, von Ziegler, L, Schläppi, C et al.(2020). Deep learning-based behavioral analysis reaches human accuracy and is capable of outperforming commercial solutions. Neuropsychopharmacology 45, 1942–52 https://doi.org/10.1038/s41386-020-0776-y\n\nData from DLC (Python):wrangle/plot (R)\n\n\n\n\n\n\n\n\nDLC Course Links\nIntroduction to DeepLabCut for Non-Programmers\nAnnotation & Labeling keypoints with napari-deeplabcut\n\n\n\n\n\nhttps://www.mackenziemathislab.org/dlc-modelzoo\nSingle-frame analysis.\n\nThis just works. It’s a small-scale version of what happens on a large-scale with all the 2d frames from your videos.\n\n\n\n\n\nMost of the DeepLabCut (DLC) tutorials are offered with Google Colab a cloud computing environment with all the software dependencies pre-installed. It really is the best first step if you want to start to understand how DLC works and how to customize it for your needs. - Click on the “Open in Colab” link on this page - Video on DLC on Google Colab - Colab instructions on how to use your own videos\n\n\n\nDeepLabCut Worshop Materials\n\n\n\n\nUF Research Computing\nUFRC Training\n\n\n\n\n\n\nYouTube video on using DeepLabCut GUI (~3 min)\nInstalling Deeplabcut https://deeplabcut.github.io/DeepLabCut/docs/installation.html\nDLC User Guide https://deeplabcut.github.io/DeepLabCut/docs/standardDeepLabCut_UserGuide.html\nNapari GUI https://deeplabcut.github.io/DeepLabCut/docs/napariGUI.html\nSlightly outdated workshop https://github.com/DeepLabCut/DeepLabCut-Workshop-Materials\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {'theme':'forest'}}%%\n\ngraph LR\n\n    subgraph Analysis\n       s6 --&gt;  s7{Inferential Stats}\n    end\n \n    subgraph ETHZ-INS/DLCAnalyzer\n        s3 --&gt; s4[Data Wrangling &lt;/br&gt; Graphing]\n        s5 --&gt; s6[Data Wrangling]\n        s6 --&gt; s4\n        \n        subgraph dlca[&lt;/tab&gt; &lt;/br&gt; Derivative Variables / Data Visualizations]\n          s4 --&gt; s5[unsupervised&lt;/br&gt; classification&lt;/br&gt; and clustering]\n        end\n    end\n\n    subgraph DeepLabCut\n\n        subgraph Training\n            s1[add keypoints]--&gt;s2[run training]\n            s2 --&gt; s2a[analyze&lt;/br&gt; training]\n            s2a --&gt;s2\n\n        end\n\n        subgraph Decoding\n            s2a --&gt; s3a[add&lt;/br&gt; videos] \n            \n        end\n        \n         \n        s3a --&gt; s3[import data&lt;/br&gt;transform]\n       \n    end\n    \n    subgraph Read-in-Data[Raw Data]\n        s0[import video] --&gt; s1\n    end\n    \n %% Notice that no text in shape are added here instead that is appended further down\n    \n\n    %% Comments after double percent signs\n\n     classDef green fill:#9f6,stroke:#333,stroke-width:0.5px;\n     classDef orange fill:#f96,stroke:#333,stroke-width:1px;\n     classDef white fill:#fff,stroke:#333,stroke-width:1px;\n     classDef sq stroke:#f66,stroke-width:1px;\n     classDef blue fill:#6699cc,stroke:#333,stroke-width:1px;\n     classDef red fill:#D32737,stroke:#FFF,stroke-width:1.5px;\n     class sq,Analysis green\n     class ETHZ-INS/DLCAnalyzer orange\n     class Training,dlca,s0 white\n     class DeepLabCut white\n     class Decoding blue\n     class Read-in-Data red\n     \n\n\n\n\n\n\n\n\n on Github/ Workshop\n\n\nUnsupervised Clustering: (R) / (R Shiny)\n\n\n\n\n\n\n\n\n\n\n[ X ] Digitize behavior videos from analog\n[ X ] Cut, Segment, Name: Subject & Session\n[ X ] Extract behavior timestamp range\n[ X ] Select behavior videos for DLC training",
    "crumbs": [
      "MPFC"
    ]
  },
  {
    "objectID": "content/github.html",
    "href": "content/github.html",
    "title": "Open Science with GitHub",
    "section": "",
    "text": "MNE-Tools Organization\nDeepLabCut Organization\nNEO/MNE mPFC-ephys\nDLC & DLCAnalyzer"
  },
  {
    "objectID": "content/rendering.html",
    "href": "content/rendering.html",
    "title": "Rendering",
    "section": "",
    "text": "The repo includes a GitHub Action that will render (build) the website automatically when you make changes to the files. It will be pushed to the gh-pages branch.\nBut when you are developing your content, you will want to render it locally."
  },
  {
    "objectID": "content/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "href": "content/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "title": "Rendering",
    "section": "Step 1. Make sure you have a recent RStudio",
    "text": "Step 1. Make sure you have a recent RStudio\nHave you updated RStudio since about August 2022? No? Then update to a newer version of RStudio. In general, you want to keep RStudio updated and it is required to have a recent version to use Quarto."
  },
  {
    "objectID": "content/rendering.html#step-2.-clone-and-create-rstudio-project",
    "href": "content/rendering.html#step-2.-clone-and-create-rstudio-project",
    "title": "Rendering",
    "section": "Step 2. Clone and create RStudio project",
    "text": "Step 2. Clone and create RStudio project\nFirst, clone the repo onto your local computer. How? You can click File &gt; New Project and then select “Version Control”. Paste in the url of the repository. That will clone the repo on to your local computer. When you make changes, you will need to push those up."
  },
  {
    "objectID": "content/rendering.html#step-3.-render-within-rstudio",
    "href": "content/rendering.html#step-3.-render-within-rstudio",
    "title": "Rendering",
    "section": "Step 3. Render within RStudio",
    "text": "Step 3. Render within RStudio\nRStudio will recognize that this is a Quarto project by the presence of the _quarto.yml file and will see the “Build” tab. Click the “Render website” button to render to the _site folder.\nPreviewing: You can either click index.html in the _site folder and specify “preview in browser” or set up RStudio to preview to the viewer panel. To do the latter, go to Tools &gt; Global Options &gt; R Markdown. Then select “Show output preview in: Viewer panel”."
  },
  {
    "objectID": "content/posts/pgso_announcement_2024/index.html",
    "href": "content/posts/pgso_announcement_2024/index.html",
    "title": "PGSO Undergraduate Forum Spring 2024: submission due March 20",
    "section": "",
    "text": "Here is an email that was sent out about the upcoming poster competition on April 18.\nThe Psychology Graduate Student Organization (PGSO) will be hosting the Undergraduate Poster Forum once again this Spring!\nThis PGSO undergraduate poster competition is a time for undergraduates to flex their research muscles and show what they’ve been working on in their labs over the past year(s). Abstracts (suggested length is 250-300 words) are due no later than Monday, March 20th at 11:59pm EST with the in-person poster session on Thursday, April 18th, from 4-5 pm on the 1st floor of the Psychology building. Posters will be judged by graduate students, with 1st, 2nd, and 3rd place posters receiving an award in the form of a gift card for $75, $50, and $25, respectively.\nPlease forward this call for abstracts to interested undergraduate students. Abstract submission link: Qualtrics Submission Form\nBest,\nHugh Farrior,\nMS Graduate Research Assistant, PGSO President\nNeurocognitive Laboratory\nUniversity of Florida\nhugh910f@ufl.edu"
  },
  {
    "objectID": "content/posts/pipeline-tutorial/index.html",
    "href": "content/posts/pipeline-tutorial/index.html",
    "title": "Tutorial on MNE-BIDS-Pipeline",
    "section": "",
    "text": "slides\n\n\n\n\n\ngraph LR;\n   epo_1--&gt;epo_1_prms;\n   epo_1_prms--&gt;epo_1_Fs;\n   epo_1_prms--&gt;epo_1_L;\n   epo_1_prms--&gt;epo_1_T;\n   epo_1_prms--&gt;epo_1_offset_pts;\n   epo_1_prms--&gt;epo_1_offset_t;\n   epo_1--&gt;epo_1_ops;\n   epo_1_ops--&gt;epo_1_seg_1;\n   epo_1_seg_1--&gt;epo_1_seg_1_prms;\n   epo_1_seg_1_prms--&gt;epo_1_seg_1_freq;\n   epo_1_seg_1_prms--&gt;epo_1_seg_1_n_cyc;\n   epo_1_seg_1_prms--&gt;epo_1_seg_1_ph_offset_r2pi;\n   epo_1_seg_1_prms--&gt;epo_1_seg_1_ph_offset_t;\n   epo_1_seg_1--&gt;epo_1_seg_1_ops;\n   epo_1_seg_1_ops--&gt;epo_1_seg_1_1;\n   epo_1_seg_1_ops--&gt;epo_1_seg_1_2;\n   epo_1_ops--&gt;epo_1_seg_2;\n   epo_1_seg_2--&gt;epo_1_seg_2_prms;\n   epo_1_seg_2_prms--&gt;epo_1_seg_2_freq;\n   epo_1_seg_2_prms--&gt;epo_1_seg_2_n_cyc;\n   epo_1_seg_2_prms--&gt;epo_1_seg_2_ph_offset_r2pi;\n   epo_1_seg_2_prms--&gt;epo_1_seg_2_ph_offset_t;\n   epo_1_seg_2--&gt;epo_1_seg_2_ops;\n   epo_1_seg_2_ops--&gt;epo_1_seg_2_1;\n   epo_1_seg_2_ops--&gt;epo_1_seg_2_2;\n   epo_2--&gt;epo_2_prms;\n   epo_2_prms--&gt;epo_2_Fs;\n   epo_2_prms--&gt;epo_2_L;\n   epo_2_prms--&gt;epo_2_T;\n   epo_2_prms--&gt;epo_2_offset_pts;\n   epo_2_prms--&gt;epo_2_offset_t;\n   epo_2--&gt;epo_2_ops;\n   epo_2_ops--&gt;epo_2_seg_1;\n   epo_2_seg_1--&gt;epo_2_seg_1_prms;\n   epo_2_seg_1_prms--&gt;epo_2_seg_1_freq;\n   epo_2_seg_1_prms--&gt;epo_2_seg_1_n_cyc;\n   epo_2_seg_1_prms--&gt;epo_2_seg_1_ph_offset_r2pi;\n   epo_2_seg_1_prms--&gt;epo_2_seg_1_ph_offset_t;\n   epo_2_seg_1--&gt;epo_2_seg_1_ops;\n   epo_2_seg_1_ops--&gt;epo_2_seg_1_1;\n   epo_2_seg_1_ops--&gt;epo_2_seg_1_2;\n   epo_2_ops--&gt;epo_2_seg_2;\n   epo_2_seg_2--&gt;epo_2_seg_2_prms;\n   epo_2_seg_2_prms--&gt;epo_2_seg_2_freq;\n   epo_2_seg_2_prms--&gt;epo_2_seg_2_n_cyc;\n   epo_2_seg_2_prms--&gt;epo_2_seg_2_ph_offset_r2pi;\n   epo_2_seg_2_prms--&gt;epo_2_seg_2_ph_offset_t;\n   epo_2_seg_2--&gt;epo_2_seg_2_ops;\n   epo_2_seg_2_ops--&gt;epo_2_seg_2_1;\n   epo_2_seg_2_ops--&gt;epo_2_seg_2_2;"
  },
  {
    "objectID": "content/posts/use_rsync_on_hpg/index.html",
    "href": "content/posts/use_rsync_on_hpg/index.html",
    "title": "Post template",
    "section": "",
    "text": "A better way is to copy all the files from the “psy4911/share” folder to your HiPerGator (HPG) folder. The rsync command for moving files between directories on HPG is described here. Copying_files_between_directories with rsync You will want to go to the shared folder on HPG first and open a terminal (see button outlined green in the schreenshot below). \nThen if you copy and paste these commands into terminal it will do the work for you: rsync -av /blue/psy4911/share/ket_ephys/ket_annot /blue/psy4911/yourusername/ket_ephys/ rsync -av /blue/psy4911/share/ket_ephys/ket_annot_segs /blue/psy4911/yourusername/ket_ephys/ rsync -av /blue/psy4911/share/ket_ephys/hi-ket /blue/psy4911/yourusername/ket_ephys/\nFor the files in the hi-ket folder there’s another script (and a package named NEO ) that’s required to convert them from .plx files to .fif files.\nRequired python packages: - NEO - NEO repo - NEO documentation - MNE - MNE Tutorial: importing data from NEO\nCode for the file conversion:\nThe main thing is that it takes 15 minutes per file on hipergator (HPG) when it’s set up like a laptop computer. When you configure HPG to run your jupter notebook in high-performance mode, it takes only a minute or two per file. So, what would take 5 hours for 20 files, ends up taking only a half hour.\nAn even bigger savings comes when doing machine learning / AI with deeplabcut on HPG."
  },
  {
    "objectID": "content/posts/open_sci_github_intro/index.html",
    "href": "content/posts/open_sci_github_intro/index.html",
    "title": "Introduction to GitHub for Open Science",
    "section": "",
    "text": "Open Science With GitHub: An Introduction"
  },
  {
    "objectID": "content/posts/open_sci_github_intro/index.html#overview",
    "href": "content/posts/open_sci_github_intro/index.html#overview",
    "title": "Introduction to GitHub for Open Science",
    "section": "Overview",
    "text": "Overview\nMuch of open science requires some technical knowledge that many novices find to be initially burdensome and confusing. Open source analysis tools are usually a work in progress. Documentation for these tools, if present at all, will be incomplete or out of date. The purpose of this slideshow is to explore concepts that will enable team coordination on software usage and code development projects. The hope is that users will be able to find the information that they need from development notes and communication between code authors. In the long-term, notes and comments about the intended function, rationale, and usage of code will be useful for outsiders but also for the project organizers and code developers themselves."
  },
  {
    "objectID": "content/posts/xpost_template3/index.html",
    "href": "content/posts/xpost_template3/index.html",
    "title": "title",
    "section": "",
    "text": "User Question:\n\n\nChatGPT Answer:"
  },
  {
    "objectID": "content/posts/share-hpg-env/index.html",
    "href": "content/posts/share-hpg-env/index.html",
    "title": "Using Custom Python environments for Jupyter Notebooks in HiPerGator",
    "section": "",
    "text": "To simply use the environment go to\n\nGetting Started: ~/.condarc configuration file\nthen to Copy the template_kernelfolder to your path\n\nFor additional info about using Python virtual environments with Conda please go the the UFRC page or the Software Carpentries pages from which these procedures were derived.\n\nUFRC: Customizing a Shared Python Environment\nCarpentries: Ch.2 Conda Environments\nConda: Using the .condarc Configuration file"
  },
  {
    "objectID": "content/posts/share-hpg-env/index.html#custom-python-environments-for-jupyter-notebooks",
    "href": "content/posts/share-hpg-env/index.html#custom-python-environments-for-jupyter-notebooks",
    "title": "Using Custom Python environments for Jupyter Notebooks in HiPerGator",
    "section": "",
    "text": "To simply use the environment go to\n\nGetting Started: ~/.condarc configuration file\nthen to Copy the template_kernelfolder to your path\n\nFor additional info about using Python virtual environments with Conda please go the the UFRC page or the Software Carpentries pages from which these procedures were derived.\n\nUFRC: Customizing a Shared Python Environment\nCarpentries: Ch.2 Conda Environments\nConda: Using the .condarc Configuration file"
  },
  {
    "objectID": "content/posts/share-hpg-env/index.html#background-from-ufrc-page",
    "href": "content/posts/share-hpg-env/index.html#background-from-ufrc-page",
    "title": "Using Custom Python environments for Jupyter Notebooks in HiPerGator",
    "section": "Background (from UFRC page)",
    "text": "Background (from UFRC page)\nMany projects that use Python code require careful management of the respective Python environments. Rapid changes in package dependencies, package version conflicts, deprecation of APIs (function calls) by individual projects, and obsolescence of system drivers and libraries make it virtually impossible to use an arbitrary set of packages or create one all-encompassing environment that will serve everyone’s needs over long periods of time. The high velocity of changes in the popular ML/DL frameworks and packages and GPU computing exacerbates the problem."
  },
  {
    "objectID": "content/posts/share-hpg-env/index.html#getting-started-conda-configuration",
    "href": "content/posts/share-hpg-env/index.html#getting-started-conda-configuration",
    "title": "Using Custom Python environments for Jupyter Notebooks in HiPerGator",
    "section": "Getting Started: Conda Configuration",
    "text": "Getting Started: Conda Configuration\n\nThe ~/.condarc configuration file\nconda‘s behavior is controlled by a configuration file in your home directory called .condarc. The dot at the start of the name means that the file is hidden from ’ls’ file listing command by default. If you have not run conda before, you won’t have this file. Whether the file exists or not, the steps here will help you modify the file to work best on HiPerGator. First load of the conda environment module on HiPerGator will put the current ‘’best practice’’ .condarc into your home directory.\nThis path will be found in your home directory (i.e., Home/&lt;myname&gt; is usually symbolized as : ~).\nHome/&lt;myname&gt;/.condarc\n\n\nconda package cache location\nconda caches (keeps a copy) of all downloaded packages by default in the ~/.conda/pkgs directory tree. If you install a lot of packages you may end up filling up your home quota. You can change the default package cache path. To do so, add or change the pkgs_dirs setting in your ~/.condarc configuration file e.g.:\npkgs_dirs:\n  - /blue/psb4934/share/conda/pkgs\nReplace psb4934 or mygroup with your actual group name, if it’s incorrect here.\n\n\nconda environment location\nconda puts all packages installed in a particular environment into a single directory. By default ‘’named’’ conda environments are created in the ~/.conda/envs directory tree. They can quickly grow in size and, especially if you have many environments, fill the 40GB home directory quota. For example, the environment we will create in this training is 5.3GB in size. As such, it is important to use ‘’path’’ based (conda create -p PATH) conda environments, which allow you to use any path for a particular environment for example allowing you to keep a project-specific conda environment close to the project data in /blue/ where you group has terrabyte(s) of space.\nYou can also change the default path for the ‘’name’’ environments (conda create -n NAME) if you prefer to keep all conda environments in the same directory tree. To do so, add or change the envs_dirs setting in the ~/.condarc configuration file e.g.:\nenvs_dirs:\n  - /blue/psb4934/share/conda/envs/mne_1_6_0/mne\nReplace mygroup with your actual group name.\n\n\nEditing your ~/.condarc file.\nOne way to edit your ~/.condarc file is to type:\nnano ~/.condarc\nIf the file is empty, paste in the text below, editing the env_dirs: and pkg_dirs: as below. If the file has contents, update those lines.\n\n\n\n\n\n\nNote\n\n\n\nYour ~/.condarc should look something like this when you are done editing (again, replacing group-akeil and USER in the paths with your actual group and username).\n\n\n\nchannels: \n  - conda-forge \n  - bioconda \n  - defaults \nenvs_dirs: \n  - /blue/psb4934/USER/conda/envs \npkgs_dirs: \n  - /blue/psb4934/USER/conda/pkgs \nauto_activate_base: false \nauto_update_conda: false \nalways_yes: false \nshow_channel_urls: false"
  },
  {
    "objectID": "content/posts/share-hpg-env/index.html#use-your-kernel-from-command-line-or-scripts",
    "href": "content/posts/share-hpg-env/index.html#use-your-kernel-from-command-line-or-scripts",
    "title": "Using Custom Python environments for Jupyter Notebooks in HiPerGator",
    "section": "Use your kernel from command line or scripts",
    "text": "Use your kernel from command line or scripts\nNow that we have our environment ready, we can use it from the command line or a script using something like:\n\n\nmodule load conda\nconda activate mne\n\n# Run my python script\npython amazing_script.py\n\n…\nor\na path based setting:\n\n# Set path to environment \n#   pre-pend to PATH variable\nenv_path=/blue/psb4934/share/mne_1_x/conda/bin\nexport PATH=$env_path:$PATH\n \n# Run my python script\npython amazing_script.py\n\n\nIf you are still not certain why the environment is not working, you can type the following on the command line conda info --envs to see the list of environments and their paths. If you don’t see /blue/psb4934/share/conda/mne_1_6_0/mne in that list of environments then something didn’t happen according to plan. If you are still having trouble, please ask for help."
  },
  {
    "objectID": "content/posts/share-hpg-env/index.html#setup-a-jupyter-kernel-for-our-environment",
    "href": "content/posts/share-hpg-env/index.html#setup-a-jupyter-kernel-for-our-environment",
    "title": "Using Custom Python environments for Jupyter Notebooks in HiPerGator",
    "section": "Setup a Jupyter Kernel for our environment",
    "text": "Setup a Jupyter Kernel for our environment\nOften, we want to use the environment in a Jupyter notebook. To do that, we can create our own Jupyter Kernel.\n\nAdd the jupyterlab package\nIn order to use an environment in Jupyter, we need to make sure we install the jupyterlab package in the environment:\nmamba install jupyterlab\n\n\nCopy the template_kernel folder to your path\nOn HiPerGator, Jupyter looks in two places for kernels when you launch a notebook:\n\n/apps/jupyterhub/kernels/ for the globally available kernels that all users can use. (Also a good place to look for troubleshooting getting your own kernel going)\n~/.local/share/jupyter/kernels for each user. (Again, your home directory and the .local folder is hidden since it starts with a dot)\n\nMake the ~/.local/share/jupyter/kernels directory: mkdir -p ~/.local/share/jupyter/kernels\nCopy the /apps/jupyterhub/template_kernel folder into your ~/.local/share/jupyter/kernels directory:\ncp -r /apps/jupyterhub/template_kernel/ ~/.local/share/jupyter/kernels/hfrl\n\n\n\n\n\n\nNote\n\n\n\nThis also renames the folder in the copy. It is important that the directory names be distinct in both your directory and the global /apps/jupyterhub/kernels/ directory.\n\n\n\n\nEdit the template_kernel files\nThe template_kernel directory has four files: the run.sh and kernel.json files will need to be edited in a text editor. We will use nano in this tutorial. The logo-64X64.png and logo-32X32.png are icons for your kernel to help visually distinguish it from others. You can upload icons of those dimensions to replace the files, but they need to be named with those names.\n\nEdit the kernel.json file\nLet’s start editing the kernel.json file. As an example, we can use:\nnano ~/.local/share/jupyter/kernels/hfrl/kernel.json\nThe template has most of the information and notes on what needs to be updated. Edit the file to look like:\n{\n \"language\": \"python\",\n \"display_name\": \"MNE v1.x\",\n \"argv\": [\n  \"~/.local/share/jupyter/kernels/mne_1_x/run.sh\",\n  \"-f\",\n  \"{connection_file}\"\n ]\n}\n\n\nEdit the run.sh file\nThe run.sh file needs the path to the python application that is in our environment. The easiest way to get that is to make sure the environment is activated and run the command: which python\nThe path it outputs should look something like: /blue/group/share/conda/envs/mne_1_x/bin/python\nCopy that path.\nEdit the run.sh file with nano:\nnano ~/.local/share/jupyter/kernels/mne_1_x/run.sh\nThe file should looks like this, but with your path:\n#!/usr/bin/bash\n\nexec /blue/psb4934/share/conda/envs/mne_1_6_0/mne/bin/python -m ipykernel \"$@\"\nIf you are doing this in a Jupyter session, refresh your page. If not, launch Jupyter.\nYour kernel should be there ready for you to use!"
  },
  {
    "objectID": "content/posts/share-hpg-env/index.html#working-with-yml-files",
    "href": "content/posts/share-hpg-env/index.html#working-with-yml-files",
    "title": "Using Custom Python environments for Jupyter Notebooks in HiPerGator",
    "section": "Working with yml files",
    "text": "Working with yml files\n\nExport your environment to an environment.yml file\nNow that you have your environment working, you may want to document its contents and/or share it with others. The environment.yml file defines the environment and can be used to build a new environment with the same setup.\nTo export an environment file from an existing environment, run:\nconda env export &gt; mne_1_x.yml\nYou can inspect the contents of this file with cat mne_1_x.yml. This file defines the packages and versions that make up the environment as it is at this point in time. Note that it also includes packages that were installed via pip.\n\n\nCreate an environment from a yaml file\nIf you share the environment yaml file created above with another user, they can create a copy of your environment using the command:\nconda env create –file mne_1_x.yml\nThey may need to edit the last line to change the location to match where they want their environment created."
  },
  {
    "objectID": "content/posts/share-hpg-env/index.html#group-environments",
    "href": "content/posts/share-hpg-env/index.html#group-environments",
    "title": "Using Custom Python environments for Jupyter Notebooks in HiPerGator",
    "section": "Group environments",
    "text": "Group environments\nIt is possible to create a shared environment accessed by a group on HiPerGator, storing the environment in, for example, /blue/psb4934/share/conda. In general, this works best if only one user has write access to the environment. All installs should be made by that one user and should be communicated with the other users in the group."
  },
  {
    "objectID": "content/posts/test_post/index.html",
    "href": "content/posts/test_post/index.html",
    "title": "Post template",
    "section": "",
    "text": "This is a test post."
  },
  {
    "objectID": "content/posts/use_ssh_mne/index.html",
    "href": "content/posts/use_ssh_mne/index.html",
    "title": "SSH to HPG3 and run MNE-BIDS-Pipeline",
    "section": "",
    "text": "Type the following command in the terminal:\nssh urgatoruser@hpg.rc.ufl.edu\nThen, follow the prompts to enter your password and Duo two-factor authentication.\nYour password will not be displayed as you type it. Then, your terminal should look like this:\nssh urgatoruser@hpg.rc.ufl.edu\nPassword: xxxxxxxx\nDuo two-factor login for urgatoruser@ufl.edu\n\nEnter a passcode or select one of the following options:\n\n 1. Duo Push to XXX-XXX-1809\n 2. Phone call to XXX-XXX-1809\n\nPasscode or option (1-2): 1\nWorks through the UF Single-sign on similar to for Canvas and gatormail.\n\n\nsrun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=2 --mem=2gb -t 90 --pty bash -i\n`[mygatoruser@login1 ~]$ srun –pty -p hpg2-compute -n 1 -N 1 -t 90 –mem=2gb /bin/bash’\n\n\n\nsrun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=4 --mem=28gb -t 60 --pty bash -i\nsrun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=4 --mem=28gb -t 60 --pty bash -i\nsrun: job 4572441 queued and waiting for resources\nsrun: job 4572441 has been allocated resources.\nNow you are on the compute node. You can check the hostname and the node list with the following commands:\necho \"Hello from $(hostname)\"\nHello from c0711a-s6.ufhpc\necho $SLURM_JOB_NODELIST\nc0711a-s6"
  },
  {
    "objectID": "content/posts/use_ssh_mne/index.html#a-single-node-2-cpu-core-job-with-2gb-of-ram-for-90-minutes-can-be-started-with-the-following-command",
    "href": "content/posts/use_ssh_mne/index.html#a-single-node-2-cpu-core-job-with-2gb-of-ram-for-90-minutes-can-be-started-with-the-following-command",
    "title": "SSH to HPG3 and run MNE-BIDS-Pipeline",
    "section": "",
    "text": "srun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=2 --mem=2gb -t 90 --pty bash -i\n`[mygatoruser@login1 ~]$ srun –pty -p hpg2-compute -n 1 -N 1 -t 90 –mem=2gb /bin/bash’"
  },
  {
    "objectID": "content/posts/use_ssh_mne/index.html#a-single-node-4-cpu-core-job-with-28gb-of-ram-for-120-minutes-can-be-started-with-the-following-command",
    "href": "content/posts/use_ssh_mne/index.html#a-single-node-4-cpu-core-job-with-28gb-of-ram-for-120-minutes-can-be-started-with-the-following-command",
    "title": "SSH to HPG3 and run MNE-BIDS-Pipeline",
    "section": "",
    "text": "srun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=4 --mem=28gb -t 60 --pty bash -i\nsrun --account=psb4934 --qos=psb4934 --ntasks=1 --cpus-per-task=4 --mem=28gb -t 60 --pty bash -i\nsrun: job 4572441 queued and waiting for resources\nsrun: job 4572441 has been allocated resources.\nNow you are on the compute node. You can check the hostname and the node list with the following commands:\necho \"Hello from $(hostname)\"\nHello from c0711a-s6.ufhpc\necho $SLURM_JOB_NODELIST\nc0711a-s6"
  },
  {
    "objectID": "content/posts/use_ssh_mne/index.html#random-tips",
    "href": "content/posts/use_ssh_mne/index.html#random-tips",
    "title": "SSH to HPG3 and run MNE-BIDS-Pipeline",
    "section": "Random Tips:",
    "text": "Random Tips:\nCreate a symbolic link to your group storage directory on Blue drive:\nln -s /blue/psb4934/ blue_psb4934\nUsing OpenOn Demand for file management\nTroubleshooting HPG3 Open OnDemand\nUsing rsync to copy/move files on HPG3\nmacOS Development Environment: iTerm2, oh-my-zsh, and VS Code"
  },
  {
    "objectID": "content/meeting-notes/index2.html",
    "href": "content/meeting-notes/index2.html",
    "title": "Meeting Notes",
    "section": "",
    "text": "Thurs (01/25/2024)\n\n\n\nConfirmed interest toward teams (GitHub ID: sub teams)\nIntroduced training plan\n\nDeveloping a Training Plan\n\nTrain like a scientist…\nBreak problem into pieces, isolate smallest parts, and cultivate capabilities. For developing specific skills, identify available resources, and then find out how to acquire technical knowledge and then practice procedures.\nWe discussed how we will use GitHub in the course and for open science.\n\n\n\n\nadd notes\npublish notes\nother business"
  },
  {
    "objectID": "content/meeting-notes/index2.html#summary-notes",
    "href": "content/meeting-notes/index2.html#summary-notes",
    "title": "Meeting Notes",
    "section": "",
    "text": "Confirmed interest toward teams (GitHub ID: sub teams)\nIntroduced training plan\n\nDeveloping a Training Plan\n\nTrain like a scientist…\nBreak problem into pieces, isolate smallest parts, and cultivate capabilities. For developing specific skills, identify available resources, and then find out how to acquire technical knowledge and then practice procedures.\nWe discussed how we will use GitHub in the course and for open science.\n\n\n\n\nadd notes\npublish notes\nother business"
  },
  {
    "objectID": "content/code.html",
    "href": "content/code.html",
    "title": "Working with Code",
    "section": "",
    "text": "We are interested in doing open science because we’d like to return the favor back to the scientific community as open science has been helpful to us.\n\nx &lt;- c(5, 15, 25, 35, 45, 55)\ny &lt;- c(5, 20, 14, 32, 22, 38)\nlm(x ~ y)\n\n\nCall:\nlm(formula = x ~ y)\n\nCoefficients:\n(Intercept)            y  \n      1.056        1.326",
    "crumbs": [
      "Code in your files"
    ]
  },
  {
    "objectID": "content/add-content.html",
    "href": "content/add-content.html",
    "title": "Customize",
    "section": "",
    "text": "How to add a new web post card.\nEdit the qmd or md files in the content folder. qmd files can include code (R, Python, Julia) and lots of Quarto markdown bells and whistles (like call-outs, cross-references, auto-citations and much more).\nEach page should start with\n---\ntitle: your title\n---\nand the first header will be the 2nd level, so ##. Note, there are situations where you leave off\n---\ntitle: your title\n---\nand start the qmd file with a level header #, but if using the default title yaml (in the --- fence) is a good habit since it makes it easy for Quarto convert your qmd file to other formats (like into a presentation)."
  },
  {
    "objectID": "content/add-content.html#edit-and-add-your-pages",
    "href": "content/add-content.html#edit-and-add-your-pages",
    "title": "Customize",
    "section": "",
    "text": "How to add a new web post card.\nEdit the qmd or md files in the content folder. qmd files can include code (R, Python, Julia) and lots of Quarto markdown bells and whistles (like call-outs, cross-references, auto-citations and much more).\nEach page should start with\n---\ntitle: your title\n---\nand the first header will be the 2nd level, so ##. Note, there are situations where you leave off\n---\ntitle: your title\n---\nand start the qmd file with a level header #, but if using the default title yaml (in the --- fence) is a good habit since it makes it easy for Quarto convert your qmd file to other formats (like into a presentation)."
  },
  {
    "objectID": "content/add-content.html#add-your-pages-the-project",
    "href": "content/add-content.html#add-your-pages-the-project",
    "title": "Customize",
    "section": "Add your pages the project",
    "text": "Add your pages the project\n\nAdd the files to _quarto.yml"
  },
  {
    "objectID": "content/links.html",
    "href": "content/links.html",
    "title": "Useful Links",
    "section": "",
    "text": "Models of Dynamical Systems\n\nMesoscopic Brain Dynamics\nSystem Dynamics Interactive Simulations\nKuramoto Model: Weakly Coupled Oscillators\n“Scale-free” Dynamics and Complexity\n1/f Noise\n\n\n\nFree Books for Python or R\n\nhttps://wesmckinney.com/book/\nhttps://r4ds.hadley.nz/\nhttps://jakevdp.github.io/PythonDataScienceHandbook/\nhttps://ggplot2-book.org/\nhttps://crumplab.com/Books.html\nhttps://github.com/christophergandrud/Rep-Res-Book\nhttps://merely-useful.tech/py-rse/\nhttps://merely-useful.tech/r-rse/\n\n\nData Science Courses\n\nhttps://merely-useful.tech/novice-r/\nhttps://github.com/merely-useful/novice-py/\nhttps://github.com/merely-useful/py-rse\n\n\n\nOpen Science\nStarting points for learning about accessibility\n\nhttps://quarto.org/\nhttps://voltrondata.com/labs\nhttps://carpentries.org/\nhttps://www.cos.io/products/osf\nhttps://ropensci.org\nhttps://posit.co/products/enterprise/academy/\nhttps://www.datacamp.com\n\n\n\nShared Docs with links to more information:\n\nhttps://github.com/asoplata/open-science-resources\nhttps://github.com/asoplata/open-computational-neuroscience-resources\n\n\n\nOpen Science Pre-publication Sites:\n\nhttps://neurolibre.org\nhttps://psyarxiv.com\nhttps://osf.io/preprints/\nhttps://arxiv.org\nCarpentries Tutorial: Introduction to Reproducible Publications with RStudio\n\n\n\nInteresting links\n\nTwo-minute Neuroscience: ketamine\n\n\n\n\nNeuroscience Information\n\nNeurodata Without Borders\nBrain Imaging Data Structure (BIDS)\nCarpentries: Working with MRI Data in Python\nCarpentries: Functional Neuroimaging Analysis in Python\nInternational Conference on Neuroinformatics (ICNF)\n\nICNF: Using Training Resources\nICNF: tutorial search\n\nNeuroStars\nNeuroHack Academy\nNeuroMatch Academy\nConcepts in Cognitive: Ontological/Taxonomy\n\nDataCamp Cheasheets:\nhttps://www.datacamp.com/tutorial/coding-best-practices-and-guidelines\nhttps://www.datacamp.com/cheatSheet/bash-and-zsh-shell-terminal-basics-cheat-sheet\nhttps://www.datacamp.com/cheatSheet/quarto-cheat-sheet-previously-known-as-r-markdown\nhttps://www.datacamp.com/cheatSheet/the-generative-ai-tools-landscape\nhttps://www.datacamp.com/cheatSheet/reshaping-data-with-pandas-in-python.\nhttps://www.datacamp.com/cheatSheet/text-data-in-python-cheat-sheet\nhttps://www.datacamp.com/cheatSheet/working-with-dates-and-times-in-python-cheat-sheet\nhttps://www.datacamp.com/cheatSheet/python-seaborn-cheat-sheet\nhttps://www.datacamp.com/cheatSheet/scipy-cheat-sheet-linear-algebra-in-python\nhttps://www.datacamp.com/cheatSheet/pandas-cheat-sheet-data-wrangling-in-python\nhttps://www.datacamp.com/cheatSheet/jupyter-notebook-cheat-sheet\nhttps://www.datacamp.com/cheatSheet/matplotlib-cheat-sheet-plotting-in-python\nhttps://www.datacamp.com/cheatSheet/getting-started-with-python-cheat-sheet\nhttps://www.datacamp.com/tutorial/a-beginners-guide-to-chatgpt-api\nhttps://www.datacamp.com/tutorial/r-markdown-tutorial\nhttps://www.datacamp.com/tutorial/what-is-a-confusion-matrix-in-machine-learning\nhttps://www.datacamp.com/tutorial/what-is-hugging-face\nhttps://www.datacamp.com/tutorial/coding-best-practices-and-guidelines\nhttps://www.datacamp.com/tutorial/introduction-to-data-pipelines-for-data-professionals\nhttps://www.datacamp.com/tutorial/a-data-scientists-guide-to-signal-processing\nhttps://www.datacamp.com/tutorial/seeing-like-a-machine-a-beginners-guide-to-image-analysis-in-machine-learning\nhttps://www.datacamp.com/tutorial/introduction-to-convolutional-neural-networks-cnns\nhttps://www.datacamp.com/tutorial/pytorch-vs-tensorflow-vs-keras\nhttps://www.datacamp.com/tutorial/the-cross-entropy-loss-function-in-machine-learning\nhttps://viso.ai/deep-learning/pytorchvideo-video-understanding/\nhttps://www.simplilearn.com/best-ai-tools-for-video-editing-article\nAmadeusGPT: a natural language interface for interactive animal behavioral analysis https://neurips.cc/media/PosterPDFs/NeurIPS%202023/72610.png?t=1701780014.8377924\nhttps://pytorch.org/audio/stable/index.html\nhttps://pytorch.org/vision/stable/index.html\nTorchvision https://paperswithcode.com/lib/torchvision#:~:text=torchvision-,The%20torchvision%20library%20consists%20of%20popular%20datasets%2C%20model%20architectures%2C%20and,video%20classification%20and%20semantic%20segmentation.\nState of the Art https://paperswithcode.com/sota\nhttps://paperswithcode.com/libraries\nhttps://paperswithcode.com/methods\nhttps://github.com/huggingface/transformers\nhttps://huggingface.co/docs/transformers/index\nCran-R Task Views\nR Task Views: Tracking Data https://cran.r-project.org/web/views/Tracking.html Carpentries https://datacarpentry.org/rr-version-control/02-git-in-github/index.html\nTen Simple Rules Collection\nhttps://www.reddit.com/r/bioinformatics/comments/12puflj/plos_computational_biology_ten_simple_rules_papers/?rdt=36960\nPLOS Computational Biology: filter “undergraduate” https://journals.plos.org/ploscompbiol/search?filterJournals=PLoSCompBiol&filterSubjects=Undergraduates&q=\nPLOS Computational Biology: filter “graduate”\nHistorical Research\nComputational Historical Thinking: With Applications in R Lincoln A. Mullen https://dh-r.lincolnmullen.com/",
    "crumbs": [
      "Useful Links"
    ]
  },
  {
    "objectID": "content/wiki.html",
    "href": "content/wiki.html",
    "title": "Open-Science-Wiki",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 10, 2023\n\n\nExample template\n\n\nRPM \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/wiki.html#lab-information",
    "href": "content/wiki.html#lab-information",
    "title": "Open-Science-Wiki",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 10, 2023\n\n\nExample template\n\n\nRPM \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/wiki.html#meeting-notes",
    "href": "content/wiki.html#meeting-notes",
    "title": "Open-Science-Wiki",
    "section": "Meeting Notes",
    "text": "Meeting Notes\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 25, 2024\n\n\nMeeting Notes\n\n\nCA \n\n\n\n\nOct 10, 2023\n\n\nMeeting template\n\n\nRPM \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/wiki.html#posts",
    "href": "content/wiki.html#posts",
    "title": "Open-Science-Wiki",
    "section": "Posts",
    "text": "Posts\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to make a Wiki post on Github\n\n\n\n\n\n\nRPM and IF\n\n\nApr 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nUsing ChatGPT to explain code\n\n\n\n\n\n\nRPM\n\n\nFeb 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPGSO Undergraduate Forum Spring 2024: submission due March 20\n\n\n\nconferences\n\n\nabstracts\n\n\nposters\n\n\n\n\n\n\n\nRPM\n\n\nFeb 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDLC methods\n\n\n\n\n\n\nRPM\n\n\nJan 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSFN poster link\n\n\n\n\n\n\nRPM\n\n\nJan 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPGSO 2023 poster link\n\n\n\n\n\n\nRPM\n\n\nJan 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDenotation & Connotation of the term Neurophysiology\n\n\n\nChatGPT\n\n\ndefinitions\n\n\n\n\n\n\n\nbot\n\n\nJan 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nInitial Survey\n\n\n\n\n\n\nRPM\n\n\nJan 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMeeting Documentation Table\n\n\n\n\n\n\nRPM\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDeveloping a training plan\n\n\n\n\n\n\nRPM\n\n\nDec 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSSH to HPG3 and run MNE-BIDS-Pipeline\n\n\n\n\n\n\nRPM\n\n\nAug 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPost template\n\n\n\n\n\n\nRPM\n\n\nMar 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with UF Research Computing\n\n\n\n\n\n\nRPM\n\n\nJan 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial on MNE-BIDS-Pipeline\n\n\n\n\n\n\nRPM\n\n\nJan 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSharing Customized Python Environments\n\n\n\nPython\n\n\ncode\n\n\nAI\n\n\ntutorial\n\n\n\n\n\n\n\nRPM\n\n\nDec 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to GitHub for Open Science\n\n\n\ncode\n\n\ndevelopment\n\n\norganization\n\n\nversion control\n\n\nslides\n\n\ntutorial\n\n\n\nIntroduction to Version control for doing open science\n\n\n\nR Mears\n\n\nJul 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPost template\n\n\n\n\n\n\nRPM\n\n\nJun 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\n\n\n\nChatGPT\n\n\n\n\n\n\n\nbot\n\n\nOct 31, 2019\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\n\n\n\n\n\n\ninitials\n\n\nOct 31, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nRPM\n\n\n\n\n\n\nRPM\n\n\nOct 31, 2019\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/miso.html",
    "href": "content/miso.html",
    "title": "Misophonia Project",
    "section": "",
    "text": "Also, known as selective sound sensitivity syndrome or sound-rage, misophonia is a disorder in which certain sounds trigger emotional or physiological responses that some might perceive as unreasonable given the circumstance. Those who have misophonia might describe it as when a sound “drives you crazy.” Their reactions can range from anger and annoyance to panic and the need to flee.\n\nMisophonia on Wikipedia\nWard, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., Traiser, C., … & Keil, A. (2022). The Relationship Between Self-Reported Misophonia Symptoms and Auditory Aversive Generalization Leaning: A Preliminary Report. Frontiers in Neuroscience, 16, 899476. https://doi.org/10.3389/fnins.2022.899476\nFarkas, A. H., Ward, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., … & Keil, A. (2023). Auditory Aversive Generalization Learning Prompts Threat-Specific Changes in Alpha-Band Activity. bioRxiv, 2023-12. https://doi.org/10.1101/2023.12.04.569971\nAccepted Pre-registration: Ward, R., Keil, A., Pouliot, J., Mears, R. P., Chiasson, P., & McIlvanie, S. (2021, September 27). Psychophysiological mechanisms underlying aversive conditioning in Misophonia.https://doi.org/10.17605/OSF.IO/E26AD\nMisophonia: Zotero Refs\n\n\n\nASMR (Autonomous sensory meridian response) is a tingling sensation that typically begins on the scalp and moves down the back of the neck and upper spine. A pleasant form of paresthesia, it has been compared with auditory-tactile synesthesia and may overlap with frisson.\n\n\n\n\nBrugge, J. F., Nourski, K. V., Oya, H., Reale, R. A., Kawasaki, H., Steinschneider, M., & Howard III, M. A. (2009). Coding of repetitive transients by auditory cortex on Heschl’s gyrus. Journal of neurophysiology, 102(4), 2358-2374. https://doi.org/10.1152/jn.91346.2008\nPopov, T., Oostenveld, R., & Schoffelen, J. M. (2018). FieldTrip made easy: an analysis protocol for group analysis of the auditory steady state brain response in time, frequency, and space. Frontiers in neuroscience, 12, 711.https://doi.org/10.3389/fnins.2018.00711\nPantev, C., Roberts, L. E., Elbert, T., Roβ, B., & Wienbruch, C. (1996). Tonotopic organization of the sources of human auditory steady-state responses. Hearing research, 101(1-2), 62-74.\nParker, D. A., Hamm, J. P., McDowell, J. E., Keedy, S. K., Gershon, E. S., Ivleva, E. I., … & Clementz, B. A. (2019). Auditory steady-state EEG response across the schizo-bipolar spectrum. Schizophrenia research, 209, 218-226. https://doi.org/10.1016/j.schres.2019.04.014\n\n\n\n\n\n\n\n\n\n%%{init: {'theme':'forest'}}%%\n\ngraph LR;\n        subgraph Sensor-level-analysis\n\n       A[Decode time-by-time &lt;/br&gt;  using a 'sliding' estimator] --&gt; B[Time-frequency &lt;/br&gt; decomposition] \n       B --&gt; C[Decoding &lt;/br&gt; based on &lt;/br&gt; common spatial patterns] \n       C --&gt; D[Noise covariance &lt;/br&gt; estimation] \n       D --&gt; E[Group average &lt;/br&gt; at the &lt;/br&gt; sensor level] \n   end\n  \n    subgraph Preprocessing\n\n       l1[Assess &lt;/br&gt; channel-wise &lt;/br&gt; data quality] --&gt; l2[Estimate &lt;/br&gt; head positions] \n       l2 --&gt; l3[Apply low- and &lt;/br&gt; high-pass filters] \n       l3 --&gt; l4[Temporal regression &lt;/br&gt; for artifact removal]\n       l4 --&gt; l5a[Fit ICA] \n       l5a --&gt; l6a[Find ICA &lt;/br&gt; artifacts] \n       l4 --&gt; l5b[Extract epochs] \n       l5b --&gt; l7[Apply ICA] \n       l6a --&gt; l7 --&gt; l8[Remove epochs &lt;/br&gt; based on  &lt;/br&gt; PTP amplitudes]  \n       l5b --&gt; l6b[Apply SSP] \n       l4 --&gt; l5c[Compute SSP] \n       l5c --&gt; l6b[Apply SSP] \n       l6b --&gt; l8[Remove epochs &lt;/br&gt; based on &lt;/br&gt; PTP amplitudes] \n       l8 --&gt; l9[Extract &lt;/br&gt; evoked data for &lt;/br&gt; each condition] \n       l9 --&gt; l10[Decode pairs of &lt;/br&gt;  conditions based on &lt;/br&gt; entire epochs] \n    end\n    \n\n   \n   %%l0[Raw Data] --&gt; l1\n   %%E --&gt; F[Output &lt;/br&gt; Statistical &lt;/br&gt; Analysis Pipeline]    \n   \n   classDef green fill:#9f6,stroke:#333,stroke-width:0.5px;\n   classDef orange fill:#f96,stroke:#333,stroke-width:1px;\n   classDef white fill:#fff,stroke:#333,stroke-width:1px;\n   classDef sq stroke:#f66,stroke-width:1px;\n   classDef blue fill:#6699cc,stroke:#333,stroke-width:1px;\n   classDef red fill:#D32737,stroke:#FFF,stroke-width:1.5px;\n     \n   class Preprocessing,Sensor-level-analysis white\n\n\n\n\n\n\n\n\n\nhttps://github.com/mne-tools\n\nhttps://mne.tools/stable/index.html\n\n\n\n\n\n\nMNE-Python is a Python package for MEG and EEG data analysis.\n\n\n\n\n\nMNE-BIDS is a Python package for converting data from the Brain Imaging Data Structure (BIDS) format to MNE-Python format.\nBIDS (Brain Imaging Data Structure) A simple and intuitive way to organize and describe your neuroimaging and behavioral data.\n\n\n\n\n\nMNE-BIDS-Pipeline is a full-flegded processing pipeline Python package for preprocessing MEG and EEG data.\n\n\n\nMNE-BIDS-Pipeline only works with BIDS-formatted raw data.\n\n\n\n\nAll parameters of the pipeline are controlled via a configuration file. Create a template:\nmne_bids_pipeline --create-config=/path/to/custom_config.py\n\nimport numpy as np\n\nstudy_name = \"ds000247\"\nbids_root = f\"~/mne_data/{study_name}\"\nderiv_root = f\"~/mne_data/derivatives/mne-bids-pipeline/{study_name}\"\n\nsubjects = [\"0002\"]\nsessions = [\"01\"]\ntask = \"rest\"\ntask_is_rest = True\n\ncrop_runs = (0, 100)  # to speed up computations\n\nch_types = [\"meg\"]\nspatial_filter = \"ssp\"\n\nl_freq = 1.0\nh_freq = 40.0\n\nrest_epochs_duration = 10\nrest_epochs_overlap = 0\n\nepochs_tmin = 0\nbaseline = None\n\n\nfrom example ds000247\n\n\n\n\nA config file controls main pipeline parameters. CLI runs all (or part with an override).\n\nRe-running a specific stage of the pipeline for additional data\n\nmne_bids_pipeline --config=custom_config.py --steps=preprocessing --subjects=0051,0052,0053\n\nRunning the pipeline with different parameters for a specific stage (e.g., changing filter cutoffs, interpolating bad channels, etc.)\n\nmne_bids_pipeline --config=custom_config.py --steps=preprocessing/ica\n\nRunning the pipeline with different parameters for a specific subject or session\n\nmne_bids_pipeline --config=custom_config.py --steps=preprocessing/ica --session=cond --subjects=0051,0052,0053\n\n\n\n\n\nBIDS projects are located two places:\n\nMiso Project /blue/psb4934/share/misophonia/bids_eeg\n\nThe derivatives folder contains the results of the pipeline, including the HTML reports. The overall structure of the derivatives folder is as follows:\nOriginal BIDS-format data are in a different location than reports.\nThe original BIDS data for subject sub-M603 is located in a subfolder named /sub-M603/eeg/ in the main BIDS folder.\n\nthe report for subject sub-M603 is located in a subfolder named /derivatives/mne-bids-pipeline/sub-M603/eeg/ in the derivatives folder.\n\nthe report for the group-level analysis (i.e., including grand averages) located in a subfolder named /derivatives/mne-bids-pipeline/sub-average/eeg/ in the derivatives folder.\n\n.\n├── dataset_description.json\n├── derivatives\n│   └── mne-bids-pipeline\n│       ├── sub-average\n│       │   └── eeg\n│       │       └──     sub-average_task-genaudi3_report.html\n│       ├── sub-M603\n│       │   └── eeg\n│       ├── sub-M604\n│       │   └── eeg\n│       .\n│       :\n│\n├── sub-M603\n│   ├── eeg\n│   └── sub-M603_scans.tsv\n├── sub-M604\n│   ├── eeg\n│   └── sub-M604_scans.tsv\n│\n.\n:\n\nSo, to find the grand aveage report, you need to go to /blue/psb4934/share/misophonia/bids_eeg/derivatives/mne-bids-pipeline/sub-average/eeg and look for the sub-average_task-genaudi3_report.html file. (For convenience, the grand average report is copied to /blue/psb4934/share/misophonia/MNE-BIDS_reports/subaverage)\n\n\nSZ/BP BIDS data: /blue/psb4934/share/mears/assr_data/bids_assr\n\nThe BIDS paths are similar for this dataset as well. The reports are located in the derivatives folder. The grand average report is located in the sub-average folder.\n\n\nFinding things on HiPerGator\n\nUF Research Computing Documentation\n\nCorrect address for python env :\nexec /blue/psb4934/share/conda/envs/mne_1_6_0/mne/bin/python -m ipykernel \"$@\"\nShared Conda environments on HiPerGator",
    "crumbs": [
      "Misophonia"
    ]
  },
  {
    "objectID": "content/miso.html#what-is-misophonia",
    "href": "content/miso.html#what-is-misophonia",
    "title": "Misophonia Project",
    "section": "",
    "text": "Also, known as selective sound sensitivity syndrome or sound-rage, misophonia is a disorder in which certain sounds trigger emotional or physiological responses that some might perceive as unreasonable given the circumstance. Those who have misophonia might describe it as when a sound “drives you crazy.” Their reactions can range from anger and annoyance to panic and the need to flee.\n\nMisophonia on Wikipedia\nWard, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., Traiser, C., … & Keil, A. (2022). The Relationship Between Self-Reported Misophonia Symptoms and Auditory Aversive Generalization Leaning: A Preliminary Report. Frontiers in Neuroscience, 16, 899476. https://doi.org/10.3389/fnins.2022.899476\nFarkas, A. H., Ward, R. T., Gilbert, F. E., Pouliot, J., Chiasson, P., McIlvanie, S., … & Keil, A. (2023). Auditory Aversive Generalization Learning Prompts Threat-Specific Changes in Alpha-Band Activity. bioRxiv, 2023-12. https://doi.org/10.1101/2023.12.04.569971\nAccepted Pre-registration: Ward, R., Keil, A., Pouliot, J., Mears, R. P., Chiasson, P., & McIlvanie, S. (2021, September 27). Psychophysiological mechanisms underlying aversive conditioning in Misophonia.https://doi.org/10.17605/OSF.IO/E26AD\nMisophonia: Zotero Refs\n\n\n\nASMR (Autonomous sensory meridian response) is a tingling sensation that typically begins on the scalp and moves down the back of the neck and upper spine. A pleasant form of paresthesia, it has been compared with auditory-tactile synesthesia and may overlap with frisson.\n\n\n\n\nBrugge, J. F., Nourski, K. V., Oya, H., Reale, R. A., Kawasaki, H., Steinschneider, M., & Howard III, M. A. (2009). Coding of repetitive transients by auditory cortex on Heschl’s gyrus. Journal of neurophysiology, 102(4), 2358-2374. https://doi.org/10.1152/jn.91346.2008\nPopov, T., Oostenveld, R., & Schoffelen, J. M. (2018). FieldTrip made easy: an analysis protocol for group analysis of the auditory steady state brain response in time, frequency, and space. Frontiers in neuroscience, 12, 711.https://doi.org/10.3389/fnins.2018.00711\nPantev, C., Roberts, L. E., Elbert, T., Roβ, B., & Wienbruch, C. (1996). Tonotopic organization of the sources of human auditory steady-state responses. Hearing research, 101(1-2), 62-74.\nParker, D. A., Hamm, J. P., McDowell, J. E., Keedy, S. K., Gershon, E. S., Ivleva, E. I., … & Clementz, B. A. (2019). Auditory steady-state EEG response across the schizo-bipolar spectrum. Schizophrenia research, 209, 218-226. https://doi.org/10.1016/j.schres.2019.04.014\n\n\n\n\n\n\n\n\n\n%%{init: {'theme':'forest'}}%%\n\ngraph LR;\n        subgraph Sensor-level-analysis\n\n       A[Decode time-by-time &lt;/br&gt;  using a 'sliding' estimator] --&gt; B[Time-frequency &lt;/br&gt; decomposition] \n       B --&gt; C[Decoding &lt;/br&gt; based on &lt;/br&gt; common spatial patterns] \n       C --&gt; D[Noise covariance &lt;/br&gt; estimation] \n       D --&gt; E[Group average &lt;/br&gt; at the &lt;/br&gt; sensor level] \n   end\n  \n    subgraph Preprocessing\n\n       l1[Assess &lt;/br&gt; channel-wise &lt;/br&gt; data quality] --&gt; l2[Estimate &lt;/br&gt; head positions] \n       l2 --&gt; l3[Apply low- and &lt;/br&gt; high-pass filters] \n       l3 --&gt; l4[Temporal regression &lt;/br&gt; for artifact removal]\n       l4 --&gt; l5a[Fit ICA] \n       l5a --&gt; l6a[Find ICA &lt;/br&gt; artifacts] \n       l4 --&gt; l5b[Extract epochs] \n       l5b --&gt; l7[Apply ICA] \n       l6a --&gt; l7 --&gt; l8[Remove epochs &lt;/br&gt; based on  &lt;/br&gt; PTP amplitudes]  \n       l5b --&gt; l6b[Apply SSP] \n       l4 --&gt; l5c[Compute SSP] \n       l5c --&gt; l6b[Apply SSP] \n       l6b --&gt; l8[Remove epochs &lt;/br&gt; based on &lt;/br&gt; PTP amplitudes] \n       l8 --&gt; l9[Extract &lt;/br&gt; evoked data for &lt;/br&gt; each condition] \n       l9 --&gt; l10[Decode pairs of &lt;/br&gt;  conditions based on &lt;/br&gt; entire epochs] \n    end\n    \n\n   \n   %%l0[Raw Data] --&gt; l1\n   %%E --&gt; F[Output &lt;/br&gt; Statistical &lt;/br&gt; Analysis Pipeline]    \n   \n   classDef green fill:#9f6,stroke:#333,stroke-width:0.5px;\n   classDef orange fill:#f96,stroke:#333,stroke-width:1px;\n   classDef white fill:#fff,stroke:#333,stroke-width:1px;\n   classDef sq stroke:#f66,stroke-width:1px;\n   classDef blue fill:#6699cc,stroke:#333,stroke-width:1px;\n   classDef red fill:#D32737,stroke:#FFF,stroke-width:1.5px;\n     \n   class Preprocessing,Sensor-level-analysis white\n\n\n\n\n\n\n\n\n\nhttps://github.com/mne-tools\n\nhttps://mne.tools/stable/index.html\n\n\n\n\n\n\nMNE-Python is a Python package for MEG and EEG data analysis.\n\n\n\n\n\nMNE-BIDS is a Python package for converting data from the Brain Imaging Data Structure (BIDS) format to MNE-Python format.\nBIDS (Brain Imaging Data Structure) A simple and intuitive way to organize and describe your neuroimaging and behavioral data.\n\n\n\n\n\nMNE-BIDS-Pipeline is a full-flegded processing pipeline Python package for preprocessing MEG and EEG data.\n\n\n\nMNE-BIDS-Pipeline only works with BIDS-formatted raw data.\n\n\n\n\nAll parameters of the pipeline are controlled via a configuration file. Create a template:\nmne_bids_pipeline --create-config=/path/to/custom_config.py\n\nimport numpy as np\n\nstudy_name = \"ds000247\"\nbids_root = f\"~/mne_data/{study_name}\"\nderiv_root = f\"~/mne_data/derivatives/mne-bids-pipeline/{study_name}\"\n\nsubjects = [\"0002\"]\nsessions = [\"01\"]\ntask = \"rest\"\ntask_is_rest = True\n\ncrop_runs = (0, 100)  # to speed up computations\n\nch_types = [\"meg\"]\nspatial_filter = \"ssp\"\n\nl_freq = 1.0\nh_freq = 40.0\n\nrest_epochs_duration = 10\nrest_epochs_overlap = 0\n\nepochs_tmin = 0\nbaseline = None\n\n\nfrom example ds000247\n\n\n\n\nA config file controls main pipeline parameters. CLI runs all (or part with an override).\n\nRe-running a specific stage of the pipeline for additional data\n\nmne_bids_pipeline --config=custom_config.py --steps=preprocessing --subjects=0051,0052,0053\n\nRunning the pipeline with different parameters for a specific stage (e.g., changing filter cutoffs, interpolating bad channels, etc.)\n\nmne_bids_pipeline --config=custom_config.py --steps=preprocessing/ica\n\nRunning the pipeline with different parameters for a specific subject or session\n\nmne_bids_pipeline --config=custom_config.py --steps=preprocessing/ica --session=cond --subjects=0051,0052,0053\n\n\n\n\n\nBIDS projects are located two places:\n\nMiso Project /blue/psb4934/share/misophonia/bids_eeg\n\nThe derivatives folder contains the results of the pipeline, including the HTML reports. The overall structure of the derivatives folder is as follows:\nOriginal BIDS-format data are in a different location than reports.\nThe original BIDS data for subject sub-M603 is located in a subfolder named /sub-M603/eeg/ in the main BIDS folder.\n\nthe report for subject sub-M603 is located in a subfolder named /derivatives/mne-bids-pipeline/sub-M603/eeg/ in the derivatives folder.\n\nthe report for the group-level analysis (i.e., including grand averages) located in a subfolder named /derivatives/mne-bids-pipeline/sub-average/eeg/ in the derivatives folder.\n\n.\n├── dataset_description.json\n├── derivatives\n│   └── mne-bids-pipeline\n│       ├── sub-average\n│       │   └── eeg\n│       │       └──     sub-average_task-genaudi3_report.html\n│       ├── sub-M603\n│       │   └── eeg\n│       ├── sub-M604\n│       │   └── eeg\n│       .\n│       :\n│\n├── sub-M603\n│   ├── eeg\n│   └── sub-M603_scans.tsv\n├── sub-M604\n│   ├── eeg\n│   └── sub-M604_scans.tsv\n│\n.\n:\n\nSo, to find the grand aveage report, you need to go to /blue/psb4934/share/misophonia/bids_eeg/derivatives/mne-bids-pipeline/sub-average/eeg and look for the sub-average_task-genaudi3_report.html file. (For convenience, the grand average report is copied to /blue/psb4934/share/misophonia/MNE-BIDS_reports/subaverage)\n\n\nSZ/BP BIDS data: /blue/psb4934/share/mears/assr_data/bids_assr\n\nThe BIDS paths are similar for this dataset as well. The reports are located in the derivatives folder. The grand average report is located in the sub-average folder.\n\n\nFinding things on HiPerGator\n\nUF Research Computing Documentation\n\nCorrect address for python env :\nexec /blue/psb4934/share/conda/envs/mne_1_6_0/mne/bin/python -m ipykernel \"$@\"\nShared Conda environments on HiPerGator",
    "crumbs": [
      "Misophonia"
    ]
  },
  {
    "objectID": "content/customizing.html",
    "href": "content/customizing.html",
    "title": "Customization",
    "section": "",
    "text": "Quarto allow many bells and whistles to make nice output. Read the documentation here Quarto documentation."
  },
  {
    "objectID": "content/customizing.html#quarto-documentation",
    "href": "content/customizing.html#quarto-documentation",
    "title": "Customization",
    "section": "",
    "text": "Quarto allow many bells and whistles to make nice output. Read the documentation here Quarto documentation."
  },
  {
    "objectID": "content/customizing.html#examples",
    "href": "content/customizing.html#examples",
    "title": "Customization",
    "section": "Examples",
    "text": "Examples\nLooking at other people’s Quarto code is a great way to figure out how to do stuff. Most will have a link to a GitHub repo where you can see the raw code. Look for a link to edit page or see source code. This will usually be on the right. Or look for the GitHub icon somewhere.\n\nQuarto gallery\nnmfs-openscapes\nFaye lab manual\nquarto-titlepages Note the link to edit is broken. Go to repo and look in documentation directory."
  },
  {
    "objectID": "content/meeting-notes/index.html",
    "href": "content/meeting-notes/index.html",
    "title": "Meeting template",
    "section": "",
    "text": "This is an example template for a new post. You can use it as a starting point for your own posts."
  },
  {
    "objectID": "content/meeting-notes/index.html#meeting-notes",
    "href": "content/meeting-notes/index.html#meeting-notes",
    "title": "Meeting template",
    "section": "Meeting notes",
    "text": "Meeting notes\n\nto be discussed\nAgenda for the meeting.\n\ntodo\ntodo\n\n\n\naccomplishments for the week\nList completed activities and notable accomplishments\n\nWhat is working…\nWhat is the current situation…\nWhat is not working…\n\n\n\npriorities for next week\n\nFinish HPG analysis, add to presentation\nMake changes to presentation based of lab meeting feedback and practice presentation\nFinish touching up manuscript draft\n\n\n\nchallenges and roadblocks\nDescribe potential challenges that have impeded or may impede your intended tasks and goals.\n\nMost of batch analysis is contingent on the job scheduler and is taking time\nI’ve had some issues with methylation adjustment and resulting files being corrupted which is pushing me back. Correcting this now\n\n\n\nLessons learned and opportunities for improvement\nList any area that might benefit from improvement within our control; problems you are trying to solve; lessons recently learned or relearned.\n\n\nLiterature\nInclude an interesting paper since the last meeting and a brief summary of why you chose this paper\n\n\nOther activities\nList other activities that are related to your work but are outside of research that you accomplished this week. This will help you appreciate and track all that you do.\n\n\nUpcoming deadlines/date and location of next meeting\n\nInclude the date and location of our next meeting so we can make sure we’re on the same calendar.*"
  },
  {
    "objectID": "content/meeting-notes/index.html#todo-list",
    "href": "content/meeting-notes/index.html#todo-list",
    "title": "Meeting template",
    "section": "TODO list",
    "text": "TODO list\n\ntodo\ntodo\ntodo\ntodo"
  },
  {
    "objectID": "content/publishing.html",
    "href": "content/publishing.html",
    "title": "Publishing",
    "section": "",
    "text": "To get your Quarto webpage to show up with the url\nyou have a few steps."
  },
  {
    "objectID": "content/publishing.html#turn-on-github-pages-for-your-repo",
    "href": "content/publishing.html#turn-on-github-pages-for-your-repo",
    "title": "Publishing",
    "section": "Turn on GitHub Pages for your repo",
    "text": "Turn on GitHub Pages for your repo\n\nTurn on GitHub Pages under Settings &gt; Pages . You will set pages to be made from the gh-pages branch and the root directory.\nTurn on GitHub Actions under Settings &gt; Actions &gt; General\n\nThe GitHub Action will automatically recreate your website when you push to GitHub after you do the initial gh-pages set-up"
  },
  {
    "objectID": "content/publishing.html#do-your-first-publish-to-gh-pages",
    "href": "content/publishing.html#do-your-first-publish-to-gh-pages",
    "title": "Publishing",
    "section": "Do your first publish to gh-pages",
    "text": "Do your first publish to gh-pages\nThe first time you publish to gh-pages, you need to do so locally.\n\nOn your local computer, open a terminal window and cd to your repo directory. Here is what that cd command looks like for me. You command will look different because your local repo will be somewhere else on your computer.\n\ncd ~/Documents/GitHub/NOAA-quarto-simple\n\nPublish to the gh-pages. In the terminal type\n\nquarto publish gh-pages\nThis is going to render your webpage and then push the _site contents to the gh-pages branch."
  },
  {
    "objectID": "content/publishing.html#dont-like-using-gh-pages",
    "href": "content/publishing.html#dont-like-using-gh-pages",
    "title": "Publishing",
    "section": "Don’t like using gh-pages?",
    "text": "Don’t like using gh-pages?\nIn some cases, you don’t want your website on the gh-pages branch. For example, if you are creating releases and you want the website pages archived in that release, then you won’t want your website pages on the gh-pages branch.\nHere are the changes you need to make if you to avoid gh-pages branch.\n\nAt the top of _quarto.yml add the following:\n\nproject: \n  type: website\n  output-dir: docs\n\nOn GitHub under Settings &gt; Pages set pages to be made from the main branch and the docs directory.\nMake sure docs is not listed in .gitignore\nPublish the site the first time locally using quarto publish from the terminal\nChange the GitHub Action because you can’t use quarto publish gh-pages. You’ll need to push to the main branch yourself (in the GitHub Action)\n\non:\n  push:\n    branches: main\n\nname: Render and Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2 \n        \n      - name: Set up R (needed for Rmd)\n        uses: r-lib/actions/setup-r@v2\n\n      - name: Install packages (needed for Rmd)\n        run: Rscript -e 'install.packages(c(\"rmarkdown\", \"knitr\", \"jsonlite\"))'\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          # To install LaTeX to build PDF book \n          # tinytex: true \n          # uncomment below and fill to pin a version\n          # version: 0.9.600\n      \n      - name: Render Quarto Project\n        uses: quarto-dev/quarto-actions/render@v2\n        with:\n          to: html\n\n      - name: Set up Git\n        run: |\n          git config --local user.email \"actions@github.com\"\n          git config --local user.name \"GitHub Actions\"\n\n      - name: Commit all changes and push\n        run: |\n          git add -A && git commit -m 'Build site' || echo \"No changes to commit\"\n          git push origin || echo \"No changes to commit\""
  },
  {
    "objectID": "content/posts/make-new-github-blogpost/index.html",
    "href": "content/posts/make-new-github-blogpost/index.html",
    "title": "How to make a Wiki post on Github",
    "section": "",
    "text": "Markdown is a markup coding language that can be used to convert content written in a plain-text format into HTML. It can be used on Github to make easy to read webpages: like the one you’re reading now!\n\n\nThe first thing you should do when creating any article is filling out the most basic information:\n\n\n\n```{yaml, eval=false}\n\n\n\n\ntitle: “Write the title of your article in quotes”\n\n\nauthor: your name goes here!\n\n\ndescription: what is your article about? briefly summarize it\n\n\ndate: write the date that you publish your article\n\n\n\n```\nAs shown above, you are always going to put these four basic pieces of information between a pair of three dashes. While the title, author, description, and date are always going to be in the section, you also have the option to add categories to this section: categories: [put your category names in a pair of brackets, seperate each category with a comma] Categories allow us to organize the articles on this wiki by topic. When you open the wiki, you will see a list of categories on the right-hand side. When you click on a category, you will be able to see any of the articles tagged with that specific category in the manner depicted above.\n\n\n\nIn addition to setting up important information about your article, markdown can be used to format your main body of text in a number of ways…\nYou can create a header by using a pound sign: # Heading\nYou can make a subheading, a sub-subheading, and onwards just by adding more pound signs: ## Subheading ### Sub-subheading\nYou can italicize or bold a sentence using asterisks: *This sentence is italicized* **This sentence is bolded**\nLinks and images can be inbedded like so: !(text)[link]\nIts also possible to inbed code directly into the text - but we’ll be going over that later."
  },
  {
    "objectID": "content/posts/make-new-github-blogpost/index.html#converting-markdown-syntax",
    "href": "content/posts/make-new-github-blogpost/index.html#converting-markdown-syntax",
    "title": "How to make a Wiki post on Github",
    "section": "",
    "text": "Markdown is a markup coding language that can be used to convert content written in a plain-text format into HTML. It can be used on Github to make easy to read webpages: like the one you’re reading now!\n\n\nThe first thing you should do when creating any article is filling out the most basic information:\n\n\n\n```{yaml, eval=false}\n\n\n\n\ntitle: “Write the title of your article in quotes”\n\n\nauthor: your name goes here!\n\n\ndescription: what is your article about? briefly summarize it\n\n\ndate: write the date that you publish your article\n\n\n\n```\nAs shown above, you are always going to put these four basic pieces of information between a pair of three dashes. While the title, author, description, and date are always going to be in the section, you also have the option to add categories to this section: categories: [put your category names in a pair of brackets, seperate each category with a comma] Categories allow us to organize the articles on this wiki by topic. When you open the wiki, you will see a list of categories on the right-hand side. When you click on a category, you will be able to see any of the articles tagged with that specific category in the manner depicted above.\n\n\n\nIn addition to setting up important information about your article, markdown can be used to format your main body of text in a number of ways…\nYou can create a header by using a pound sign: # Heading\nYou can make a subheading, a sub-subheading, and onwards just by adding more pound signs: ## Subheading ### Sub-subheading\nYou can italicize or bold a sentence using asterisks: *This sentence is italicized* **This sentence is bolded**\nLinks and images can be inbedded like so: !(text)[link]\nIts also possible to inbed code directly into the text - but we’ll be going over that later."
  },
  {
    "objectID": "content/posts/make-new-github-blogpost/index.html#importance-of-yaml",
    "href": "content/posts/make-new-github-blogpost/index.html#importance-of-yaml",
    "title": "How to make a Wiki post on Github",
    "section": "Importance of YAML",
    "text": "Importance of YAML"
  },
  {
    "objectID": "content/posts/make-new-github-blogpost/index.html#quarto",
    "href": "content/posts/make-new-github-blogpost/index.html#quarto",
    "title": "How to make a Wiki post on Github",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "content/posts/make-new-github-blogpost/index.html#creating-a-folder",
    "href": "content/posts/make-new-github-blogpost/index.html#creating-a-folder",
    "title": "How to make a Wiki post on Github",
    "section": "Creating a Folder",
    "text": "Creating a Folder\nIn order to create an article, you first have to create a folder in which you will create an index.qmd file. The index.qmd file is where you will be writing in Markdown to create your article. The process of folder creation is depicted in the gif below."
  },
  {
    "objectID": "content/posts/make-new-github-blogpost/index.html#embedding-code",
    "href": "content/posts/make-new-github-blogpost/index.html#embedding-code",
    "title": "How to make a Wiki post on Github",
    "section": "Embedding Code",
    "text": "Embedding Code"
  },
  {
    "objectID": "content/posts/neurophysiol_def_bot/index.html",
    "href": "content/posts/neurophysiol_def_bot/index.html",
    "title": "Denotation & Connotation of the term Neurophysiology",
    "section": "",
    "text": "User Question:\n\nDefine the denotation and connotations of the term, neurophysiology.\n\nChatGPT Answer:\n\nNeurophysiology is a branch of physiology and neuroscience that studies the functioning of the nervous system. To break this down in terms of denotation and connotations:\nDenotation (Literal Meaning):\nNeurophysiology is a scientific discipline focused on understanding how the nervous system functions. This includes studying the electrical and biochemical processes that occur in neurons (nerve cells) and neural circuits. The field encompasses a range of topics, from how neurons communicate with each other to how these processes result in motor functions, sensory perceptions, and cognitive abilities. Neurophysiologists use various techniques, such as electrophysiological recordings (like EEG and single neuron recording), to study the nervous system in both healthy and diseased states.\nConnotations (Associated Meanings and Implications):\n\nComplexity and Sophistication: Neurophysiology is often associated with the complexity of the brain and nervous system, one of the most intricate and sophisticated systems in the human body.\nCutting-Edge Science: The field is viewed as highly advanced and at the forefront of scientific research, particularly in understanding brain function and treating neurological disorders.\nInterdisciplinary Nature: Neurophysiology is inherently interdisciplinary, intersecting with fields like biology, psychology, medicine, and even engineering (in the context of developing neurological devices and interfaces).\nMedical and Health Implications: There’s a strong association with medical applications, particularly in diagnosing and treating neurological disorders such as epilepsy, Alzheimer’s disease, and Parkinson’s disease.\nTechnological Innovation: The field is often linked with technological advancements, especially in medical imaging and neuroimaging techniques like MRI and PET scans, which are crucial for studying brain function.\nEthical and Philosophical Questions: Neurophysiology can evoke discussions about deeper ethical and philosophical issues, such as the nature of consciousness, free will, and the mind-body connection.\n\nIn summary, while the denotation of neurophysiology refers to its scientific study of the nervous system, its connotations bring in aspects of complexity, interdisciplinary research, medical relevance, technological innovation, and deeper philosophical inquiries."
  },
  {
    "objectID": "content/posts/meeting_documentation/index.html",
    "href": "content/posts/meeting_documentation/index.html",
    "title": "Meeting Documentation Table",
    "section": "",
    "text": "Meeting types, roles, and responsibilities\n\n\n\n\n\n\n\n\n\n\nActivity\nTitle (for docs)\nOrganizer\nNote Taker\nSend Agenda/ Paper\nPublish Notes/Presentation\n\n\n\n\n1:1\n&lt;your name&gt;\nTeam member\nTeam member\n24 hrs before\n24 hrs after\n\n\n2:1\n&lt;your name&gt;\nJunior team member\nJunior team member\n24 hrs before\n24 hrs after\n\n\nClass Meeting: Literature discusssion\nClass meeting: Literature discussion\npresenter\n\n1 week before\n24 hrs after\n\n\nClass Meeting: Skills Session\nClass meeting: Tech\npresenter\n\n\n24 hrs after\n\n\nClass Meeting: Research\nClass meeting: &lt;your name&gt;&lt;date&gt;: Research\npresenter\npresenter\n\n24 hrs after\n\n\nSupervisory\nSupervisory\n&lt;your name&gt;&lt;date&gt;\npresenter\npresenter\n1 week before\n24 hrs after\n\n\nOther meeting\n&lt;meeting name&gt;&lt;date&gt;\nSenior team member\nJunior team member\n1 week before\n24 hrs after\n\n\n\n\n\n\n\n\nEach meeting has an organizer, who posts and emails the agenda. Most meetings have a note taker.\n\nCommunicate the agenda in advance.\n\nRationale: ensure everyone is fully prepared for the meeting. Meetings should be used for things that are more complex and nuanced than those that can be dealt with over email.\n\nAgenda content\n\nAgenda: : a numbered list of items or questions to discuss, each one no more than one line.\nShort explanatory notes can be later on in the document, if required.\n\nPosting the agenda\n\nCreating agenda for a new meeting or series\n\nCreate\n\nConverting a one-off meeting to a series\n\nCreate\n\n\nSending the agenda\n\nCreate an email with subject: “Agenda: ⟨title from Table 1⟩, ⟨date⟩”\nCopy the contents of the OneDrive Doc into the text of an email.\nAt the bottom, paste the URL of the agenda on OneDrive Doc (even if you have sent out this URL before).\nSend to all participants.\nPlease email all participants any later updates to the agenda.\n\n\n\n\n\n\nEdit the Agenda Google Doc to include minutes directly underneath individual agenda items.\n\nMinutes content\n\nRecord any decisions made in the meeting.\nAction items. For any actions discussed that need execution by meeting participants, put “ACTION: ⟨responsible person’s name⟩: ⟨action to be taken⟩” with “ACTION:” in bold and all caps. This includes any actions that need to be taken by Michael or other faculty.\nUsually it is unnecessary to take detailed notes, outside the categories of (i) records of decision and (ii) action items.\n\n\nSending the minutes:\n\nAs soon as possible after the meeting (within 24 hours), copy the contents of the agenda with notes into the text of an email and send it to all participants with the URL.\nCopy the notes into your lab notebook for a durable record."
  },
  {
    "objectID": "content/posts/meeting_documentation/index.html#overview-of-meeting-notes",
    "href": "content/posts/meeting_documentation/index.html#overview-of-meeting-notes",
    "title": "Meeting Documentation Table",
    "section": "",
    "text": "Meeting types, roles, and responsibilities\n\n\n\n\n\n\n\n\n\n\nActivity\nTitle (for docs)\nOrganizer\nNote Taker\nSend Agenda/ Paper\nPublish Notes/Presentation\n\n\n\n\n1:1\n&lt;your name&gt;\nTeam member\nTeam member\n24 hrs before\n24 hrs after\n\n\n2:1\n&lt;your name&gt;\nJunior team member\nJunior team member\n24 hrs before\n24 hrs after\n\n\nClass Meeting: Literature discusssion\nClass meeting: Literature discussion\npresenter\n\n1 week before\n24 hrs after\n\n\nClass Meeting: Skills Session\nClass meeting: Tech\npresenter\n\n\n24 hrs after\n\n\nClass Meeting: Research\nClass meeting: &lt;your name&gt;&lt;date&gt;: Research\npresenter\npresenter\n\n24 hrs after\n\n\nSupervisory\nSupervisory\n&lt;your name&gt;&lt;date&gt;\npresenter\npresenter\n1 week before\n24 hrs after\n\n\nOther meeting\n&lt;meeting name&gt;&lt;date&gt;\nSenior team member\nJunior team member\n1 week before\n24 hrs after\n\n\n\n\n\n\n\n\nEach meeting has an organizer, who posts and emails the agenda. Most meetings have a note taker.\n\nCommunicate the agenda in advance.\n\nRationale: ensure everyone is fully prepared for the meeting. Meetings should be used for things that are more complex and nuanced than those that can be dealt with over email.\n\nAgenda content\n\nAgenda: : a numbered list of items or questions to discuss, each one no more than one line.\nShort explanatory notes can be later on in the document, if required.\n\nPosting the agenda\n\nCreating agenda for a new meeting or series\n\nCreate\n\nConverting a one-off meeting to a series\n\nCreate\n\n\nSending the agenda\n\nCreate an email with subject: “Agenda: ⟨title from Table 1⟩, ⟨date⟩”\nCopy the contents of the OneDrive Doc into the text of an email.\nAt the bottom, paste the URL of the agenda on OneDrive Doc (even if you have sent out this URL before).\nSend to all participants.\nPlease email all participants any later updates to the agenda.\n\n\n\n\n\n\nEdit the Agenda Google Doc to include minutes directly underneath individual agenda items.\n\nMinutes content\n\nRecord any decisions made in the meeting.\nAction items. For any actions discussed that need execution by meeting participants, put “ACTION: ⟨responsible person’s name⟩: ⟨action to be taken⟩” with “ACTION:” in bold and all caps. This includes any actions that need to be taken by Michael or other faculty.\nUsually it is unnecessary to take detailed notes, outside the categories of (i) records of decision and (ii) action items.\n\n\nSending the minutes:\n\nAs soon as possible after the meeting (within 24 hours), copy the contents of the agenda with notes into the text of an email and send it to all participants with the URL.\nCopy the notes into your lab notebook for a durable record."
  },
  {
    "objectID": "content/posts/DLC_methods_spring_2023/index.html",
    "href": "content/posts/DLC_methods_spring_2023/index.html",
    "title": "DLC methods",
    "section": "",
    "text": "How to write a DeepLabCut Methods Section\nconfig.yaml file"
  },
  {
    "objectID": "content/posts/DLC_methods_spring_2023/index.html#methods-items",
    "href": "content/posts/DLC_methods_spring_2023/index.html#methods-items",
    "title": "DLC methods",
    "section": "Methods items",
    "text": "Methods items\nFor body part tracking we used DeepLabCut (version 2.X.X) [Mathis et al, 2018, Nath et al, 2019]. - DLC v.2.2.6 ?\nSpecifically, we labeled X number of frames taken from X videos/animals (then X% was used for training (default is 95%).\n\n30 frames\n3 animals\n3 videos\n28 frames were used for training, i.e., the the DLC default proportion 95%\n\nWe used a X-based neural network (i.e., X = ResNet-50) with default parameters for 500,000 training iterations. [see citations below]\n\nNOTE: I’m not certain what X refers to for X-based; X = ResNet-50\nX?: 500,000 training iterations\n\nWe validated with X number of shuffles,\n\n1 shuffle\n\nand found the test error was: X pixels, train: X pixels (image size was X by X).\n\ntest error was 37.38 pixels\ntraining error was 1.73 pixels\nimage size was 720 by X 480 pixels\n\nWe then used a p-cutoff of X (i.e. 0.9) to condition the X,Y coordinates for future analysis.\n\nvery consevative p-cutoff of 0.6 for X,Y coordinates for future analysis\n\nThis network was then used to analyze eight videos from similar experimental settings.\n\nReferences\nInsafutdinov, E., Pishchulin, L., Andres, B., Andriluka, M. & Schiele, B. DeeperCut: A deeper, stronger, and faster multi-person pose estimation model. In European Conference on Computer Vision, 34–50 (Springer, 2016).\nHe, K., Zhang, X., Ren, S. & Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, 770–778 (2016). URL https://arxiv.org/abs/ 1512.03385."
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html",
    "title": "Open Neuro",
    "section": "",
    "text": "R for data science\nGGplot2\n\n\n\n\n\nPython data science handbook\nPython for data analysis, 3rd ed.\n\n\n\n\n\nR Tidymodels"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#books",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#books",
    "title": "Open Neuro",
    "section": "",
    "text": "R for data science\nGGplot2\n\n\n\n\n\nPython data science handbook\nPython for data analysis, 3rd ed.\n\n\n\n\n\nR Tidymodels"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#courses",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#courses",
    "title": "Open Neuro",
    "section": "Courses",
    "text": "Courses\n\nPython ML from scratch"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#skills",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#skills",
    "title": "Open Neuro",
    "section": "Skills",
    "text": "Skills\n\ntables/dataframe\ndata manipulation\ndata visualization"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#data-concepts",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#data-concepts",
    "title": "Open Neuro",
    "section": "Data Concepts",
    "text": "Data Concepts\n\ntidy data\ndata types: lists, arrays, dataframes, matrices\ndataytpes: int, float, string, boolean\ndata structures: series (1d), dataframe (2d), panel (3d)\ndata objects: series, dataframe, panel\ndata manipulation: indexing, slicing, filtering, sorting, grouping, joining, reshaping\ndata visualization: line plots, bar plots, histograms, scatter plots, box plots, heatmaps, subplots\ntidy data: each variable is a column, each observation is a row, each type of observational unit is a table\ndata types: lists, arrays, dataframes, matrices"
  },
  {
    "objectID": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#functions-and-patterns",
    "href": "content/posts/osci_concepts_skills/rpy_skills_concepts.html#functions-and-patterns",
    "title": "Open Neuro",
    "section": "Functions and Patterns",
    "text": "Functions and Patterns\n\nfunctions: map, apply, filter, reduce, groupby, join, melt, pivot, transpose, stack, unstack, pivot_table, crosstab, merge, concat, append, sort, sort_values, sort_index, sortlevel,\ngrammar of graphics\nunit tests\ndata pipelines"
  },
  {
    "objectID": "content/posts/meaning_of_gbo/index.html",
    "href": "content/posts/meaning_of_gbo/index.html",
    "title": "title",
    "section": "",
    "text": "There are two new groups set in in Canvas, and each has a main page.\n\nMisophonia project is working on ERP Bootcamp\nmPFC-Ketamine project is working on Collab and watching YouTube videos about DeepLabCut\n\nYesterday we discussed a (very broad) overview of the relationship of cellular-level to macroscopic EEG signals, especially to gamma. This is the first time on the project that I attempted to describe these relationships. Clearly, there was room for improvement, but it was good to introduce some concepts that we will revisit. Although some people might not be interested in some of the details, there were two main points to highlight. First, gamma rhythms indicate that information being passed in brain circuits. When gamma in a sufficiently large number of neurons is synchronized, it can be measured noninvasively, but usually gamma occurs in small amounts and can typically be measured best by invasive ECOG or implanted depth electrodes. Secondly, Anterior Cingulate Cortex (ACC) is a region of Medial Prefrontal Cortex (MPFC) that is functionally correlated with sensory salience, emotional and motivational information. This ACC/MPFC region is one of the few regions of cortex that has reciprocal connections with several modulatory brain regions that are the source of arousal, vigilance, attention, orienting responses, and as such ACC/MPFC is positioned to orchestrate brain states of alertness, neuroplasticity, and learning.\nFernandez-Ruiz, A., Sirota, A., Lopes-dos-Santos, V., & Dupret, D. (2023). Over and above frequency: gamma oscillations as units of neural circuit operations. Neuron, 111(7), 936-953. https://doi.org/10.1016/j.neuron.2023.02.026\nIn the next paper,\nHere’s an article we briefly discussed about the harmful effects of being bullied or victimized in relation to medial prefrontal cortex function (i.e., in conditions negatively correlated with social-support). https://neurosciencenews.com/bullying-glutamate-psychosis-25560/\nOkada, N., Yahata, N., Koshiyama, D. et al. (2024). Longitudinal trajectories of anterior cingulate glutamate and subclinical psychotic experiences in early adolescence: the impact of bullying victimization. Mol Psychiatry. https://doi.org/10.1038/s41380-023-02382-8\nThe study that the news release highlights was done at Univ. of Tokyo, and the article is relevant to our research because this part of prefrontal cortex is sort of a barometer for the brain’s response to salient, stressful, and aversive chronic experiences. From other research we know that anything that can lessen the impact of this type of constant, uncontrollable stress is protective during this critical developmental time.\nLazarewicz, M. T., Ehrlichman, R. S., Maxwell, C. R., Gandal, M. J., Finkel, L. H., & Siegel, S. J. (2010). Ketamine Modulates Theta and Gamma Oscillations. Journal of Cognitive Neuroscience, 22(7), 1452–1464. https://doi.org/10.1162/jocn.2009.21305\nAlexander, L., Jelen, L. A., Mehta, M. A., & Young, A. H. (2021). The anterior cingulate cortex as a key locus of ketamine’s antidepressant action. Neuroscience & Biobehavioral Reviews, 127, 531–554. https://doi.org/10.1016/j.neubiorev.2021.05.003"
  },
  {
    "objectID": "content/posts/xpost_template/discussion_papers/index.html",
    "href": "content/posts/xpost_template/discussion_papers/index.html",
    "title": "RPM",
    "section": "",
    "text": "Keiler,L.S. 2018.Teachers’ roles and identities in student-centered classrooms. International journal of STEM education, 5, 1-20.\nHendricks, A. E. (2023). Successful and sustainable undergraduate research in data science. arXiv preprint arXiv:2303.10792."
  },
  {
    "objectID": "content/posts/training_plan_dev/index.html",
    "href": "content/posts/training_plan_dev/index.html",
    "title": "Developing a training plan",
    "section": "",
    "text": "1. Aims/Goals - What do you want to learn?\n2. Resources - What resources are available to you?\n3. Approaches - What approaches are available to you?\n4. Methods - What methods are available to you?\n5. Steps - What steps do you take to learn?\n6. Implementation - Who will collaborate and facilitate?\n7. Roles and Responsibilities - Who will do what?\n7. Assessment - How will you know you are learning?\n8. Evaluation - How will you know you have learned?"
  },
  {
    "objectID": "content/posts/training_plan_dev/index.html#essential-components-of-a-training-plan",
    "href": "content/posts/training_plan_dev/index.html#essential-components-of-a-training-plan",
    "title": "Developing a training plan",
    "section": "",
    "text": "1. Aims/Goals - What do you want to learn?\n2. Resources - What resources are available to you?\n3. Approaches - What approaches are available to you?\n4. Methods - What methods are available to you?\n5. Steps - What steps do you take to learn?\n6. Implementation - Who will collaborate and facilitate?\n7. Roles and Responsibilities - Who will do what?\n7. Assessment - How will you know you are learning?\n8. Evaluation - How will you know you have learned?"
  },
  {
    "objectID": "content/posts/training_plan_dev/index.html#meta-learning",
    "href": "content/posts/training_plan_dev/index.html#meta-learning",
    "title": "Developing a training plan",
    "section": "Meta-learning",
    "text": "Meta-learning\n\n\n\n\n\n\n\ngraph TD;\n    A[Define Aims/Goals] --&gt; B[Identify Resources]\n    B --&gt; C[Inquire about approaches]\n    C --&gt; D[Iterrogate methods]\n    D --&gt; E[Take step]\n    E --&gt; F[Recursively repeat...]--&gt;A\n\n\n\n\n\n\n\n\n\n\nLearn as a scientist\n\nHow do I learn how to do … ?\n\n\n\nCultivating capabilities\n\nHow do I find out what I need to learn to do … ?\n\n\n\nAcquire specific knowledge/skills\n\nWhat initial steps do I take?"
  },
  {
    "objectID": "content/posts/training_plan_dev/index.html#open-science-approach-to-computational-reproducibility",
    "href": "content/posts/training_plan_dev/index.html#open-science-approach-to-computational-reproducibility",
    "title": "Developing a training plan",
    "section": "Open Science Approach to Computational Reproducibility",
    "text": "Open Science Approach to Computational Reproducibility\n\n\nSpecificity\n\n\n\n\n\ngraph TD;\n    A[coarse] -----&gt; B[granular]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngraph LR;\n    A[Abstract] ---&gt; |Representativeness &lt;/br&gt; &lt;/br&gt; &lt;/tab&gt; | B[Concrete]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing Environment\nWorkflow /  Pipeline\n\n\nRaw Data  & Code\nAnalysis Derivatives-derived variables-stats/figures\n\n\n\n\n\n\nComputing Environment\n\nlearn how computing works (computing abstractions, operating systems graphics hardware, applications/software, filesystems, etc.)\nlearn shell scripting for generalizing tasks across hardware/operating systems\n\n\n\nworkflow/pipeline\n\nreproducibility/open science\n\n\n\nraw data / code\n\nlearn how to use this\ndataframe concepts\n\n\n\nDerivatives\n\ndata wrangling in Python/R\nlearn how to graph in Python/R\nimplementation of intermediate steps\ninferential statistics\n\n\n\nanother graph\n\n\n\n\n\n%%{init: {'theme':'forest'}}%%\ngraph LR\n\n    subgraph DeepLabCut\n        direction BT\n        subgraph Training\n            s1--&gt;s2\n\n        end\n\n        subgraph Decoding\n            s3 --&gt; s1\n            \n        end\n\n        s2 --&gt;s3 \n       \n    end\n \n\n    subgraph ETHZ-INS/DLCAnalyzer\n        direction BT\n        s3 --&gt; s4\n        s5 --&gt; s6 \n        s6 --&gt; s4\n        \n        subgraph dlca[Derivative Variables &lt;/br&gt; Data Visualizations]\n          s4 --&gt; s5\n        end\n    end\n\n    subgraph Analysis\n       s6 --&gt;  s7{Inferential Stats}\n    end\n \n\n %% Notice that no text in shape are added here instead that is appended further down\n    \n\n    %% Comments after double percent signs\n\n     classDef green fill:#9f6,stroke:#333,stroke-width:0.5px;\n     classDef orange fill:#f96,stroke:#333,stroke-width:1px;\n     classDef white fill:#fff,stroke:#333,stroke-width:1px;\n     classDef sq stroke:#f66,stroke-width:1px;\n     classDef blue fill:#6699cc,stroke:#333,stroke-width:1px;\n     class sq,Analysis green\n     class ETHZ-INS/DLCAnalyzer orange\n     class Training,dlca white\n     class DeepLabCut white\n     class Decoding blue"
  },
  {
    "objectID": "content/posts/bot_code_descriptions/index.html",
    "href": "content/posts/bot_code_descriptions/index.html",
    "title": "Using ChatGPT to explain code",
    "section": "",
    "text": "Link to Markdown document\nChatGPT conversation in data analyst mode"
  },
  {
    "objectID": "content/posts/new_hpg3/index.html",
    "href": "content/posts/new_hpg3/index.html",
    "title": "Getting Started with UF Research Computing",
    "section": "",
    "text": "Course Registration\n\nIf you are in PSB4934: skip the next step.\nIf you’re not in PSB4934: Fill out PSY4911 form and complete 2 training topics i.e., required by Psychology:\n\nFERPA Basics\nMaintaining a Safe and Respectful Campus\n\n\n\n\nOrientation to High-Performance Computing on HiPerGator3 (HPG)\n\nGo to HiPerGator3 New User Training i.e.,req by UF RC\nComplete the required Coursera training\nGo to the UFRC Getting Started page\nBookmark the UFRC Help and Documentation page in your browser"
  },
  {
    "objectID": "content/posts/interest_survey/index.html",
    "href": "content/posts/interest_survey/index.html",
    "title": "Initial Survey",
    "section": "",
    "text": "Please start the semester by responding to this survey. The goal of this activity is to begin to identify personal priorities and objectives and to think critically about your immediate and short-term goals in this course in relation to your long-term plans."
  },
  {
    "objectID": "content/posts/interest_survey/index.html#immediate-priorities",
    "href": "content/posts/interest_survey/index.html#immediate-priorities",
    "title": "Initial Survey",
    "section": "Immediate Priorities",
    "text": "Immediate Priorities\n\nEnvisioning Your Learning Journey:\nReflect on the cognitive and behavioral neuroscience concepts and knowledge areas you find most compelling. How would you like to integrate these into your coursework this semester to create a personalized learning journey?\nResearch Objectives:\nConsidering the research techniques and methodologies covered in this course, what specific research skills do you aim to develop this semester, and how do they align with your academic interests?\nAdditional Aspirations:\nBeyond the structured curriculum, what additional personal or professional goals would you like to set for yourself this semester, and how might these enhance your experience in the field of neuroscience?\nLong-Term Vision:\nCan you outline your provisional 1-, 3-, and 5-year goals related to your future career? How have these goals evolved since the last time you considered them, and how do they inform your current academic trajectory?\nInstructor’s Role:\nWhat specific support or resources from me, as your instructor, would be most beneficial in helping you achieve your academic and research goals this semester?\nAnticipated Challenges:\nWhat concerns or challenges do you anticipate facing next year in your endeavors, and how might you proactively address them?\nOvercoming Obstacles:\nAre there any particular worries you have about this upcoming semester that you would like to share, and what steps can I take to support you in overcoming these hurdles?\n\nThink strategically about your long-term education and research priorities, and set goals that are not only focused on immediate outcomes but also aligned with long-term academic and/or career aspirations. Moreover, these questions are an invitation for you to consider and articulate the role they would like me, as your course instructor, to play in your educational journey, fostering a collaborative learning environment for you and your classmates."
  },
  {
    "objectID": "content/acknowledgements.html",
    "href": "content/acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "This repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland.",
    "crumbs": [
      "Acknowledgements"
    ]
  },
  {
    "objectID": "content/rmarkdown.html",
    "href": "content/rmarkdown.html",
    "title": "R Markdown",
    "section": "",
    "text": "You can include R Markdown files in your project."
  },
  {
    "objectID": "content/rmarkdown.html#r-markdown",
    "href": "content/rmarkdown.html#r-markdown",
    "title": "R Markdown",
    "section": "R Markdown",
    "text": "R Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "content/rmarkdown.html#including-plots",
    "href": "content/rmarkdown.html#including-plots",
    "title": "R Markdown",
    "section": "Including Plots",
    "text": "Including Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot."
  },
  {
    "objectID": "content/lab-information/lab-information-example-post/index.html",
    "href": "content/lab-information/lab-information-example-post/index.html",
    "title": "Example template",
    "section": "",
    "text": "This is an example template for a new post. You can use it as a starting point for your own posts."
  }
]